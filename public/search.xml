<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hexo + GitHub Pages搭建个人博客</title>
    <url>/2021/09/16/Hexo-GitHubPages/</url>
    <content><![CDATA[<center>本博客搭建过程中参考了许多教程。本文用于记录搭建过程，以及出现的一些小问题</center>  
<span id="more"></span>  

<br>  
<br>  

<p>有需要学习搭建博客的朋友可直接参考他人成熟的教程。本文参考教程：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/70240127">Hexo+Github Pages快速实现个人网站</a><br> 搭建流程较为清晰，整体框架都有，不想详细了解每一个步骤只是想成功搭建一个博客参考这个教程就够</li>
<li><a href="https://juejin.cn/post/6844904131266609165">彻底搞懂如何使用Hexo+GitHubPages搭建个人博客</a><br> 对于各种概念的解释都很详细，能够学习到很多知识，有助于未来对博客进行魔改升级等高级操作</li>
<li><a href="https://hexo.io/zh-cn/docs/">Hexo官方说明文档</a><br> Hexo官方说明文档，目前更新版本为1/9/2021。内容步骤简洁明了，跟着一步步做不会出大的差错，如有问题也可以直接提交</li>
<li><a href="https://docs.github.com/en/pages/getting-started-with-github-pages/creating-a-github-pages-site">GitHub Pages官方说明文档</a><br> GitHub Pages官方说明文档，参考性不如前面三个链接，但也能提供一部分支持。</li>
</ol>
<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><h3 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h3><p>Mac和Linux系统的电脑已经预装了git.<br>Windows系统的电脑可以从官网(<a href="https://git-scm.com/downloads">https://git-scm.com/downloads</a> )下载相应的版本，安装过程中选择默认选项即可。<br>由于之前简单使用过gitee加git存代码，git的配置在当初已经完成。搜索“git使用”能够找到很多有用的教程。</p>
<h3 id="Node-js"><a href="#Node-js" class="headerlink" title="Node.js"></a>Node.js</h3><p>可从官网 (<a href="https://nodejs.org/en/">https://nodejs.org/en/</a>)直接下载安装，可根据需求下载最新版本或推荐版本。需要注意的是，目前Hexo官网给出的建议是Node.js版本需不低于10.13，建议使用Node.js 12.0及以上版本。此处下载了Nodejs官网的推荐版本(recommended for most users)，14.17.6 LTS.<br>由于对Node.js并不了解，安装过程中直接选择了Automatically install the necessary tools.如果想更深入了解安装过程及自定义安装，可参考官方给出的详细安装教程(<a href="https://github.com/nodejs/node-gyp#on-windows">https://github.com/nodejs/node-gyp#on-windows</a>)</p>
<h3 id="Hexo-1"><a href="#Hexo-1" class="headerlink" title="Hexo"></a>Hexo</h3><h4 id="检查Git和node-js安装情况"><a href="#检查Git和node-js安装情况" class="headerlink" title="检查Git和node.js安装情况"></a>检查Git和node.js安装情况</h4><p>安装Hexo需要git和node.js安装完成。检查电脑中这两项安装完成后，即可安装Hexo。可使用查看版本来检查是否安装成功。  </p>
<pre><code>$ npm -v  
$ node -v  
$ git --version  
</code></pre>
<h4 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h4><p>上述安装成功后，只需要使用npm即可完成Hexo的安装  </p>
<pre><code>$ npm install -g hexo-cli  
</code></pre>
<p>对于熟悉 npm 的进阶用户，可以仅局部安装 hexo 包  </p>
<pre><code>$ npm install hexo
</code></pre>
<h4 id="检查安装是否成功"><a href="#检查安装是否成功" class="headerlink" title="检查安装是否成功"></a>检查安装是否成功</h4><p>依然使用查看版本号的方式检查安装是否成功，运行命令：  </p>
<pre><code>$ hexo - v
</code></pre>
<h4 id="建站"><a href="#建站" class="headerlink" title="建站"></a>建站</h4><pre><code>$ hexo init &lt;blogname&gt; #此处blogname可以自己起名字，此步要在空目录下进行
$ cd blog  #进入blog目录
$ npm install  #它会根据package.json依赖配置文件自动下载安装所需要的依赖模块node_modules
$ hexo generate  #生成静态文件, 缩写 $ hexo g
$ hexo server  #开启本地服务, 此时通过 http://localhost:4000 就可以访问默认样式的博客, 缩写$ hexo s
</code></pre>
<h4 id="小小的Debug"><a href="#小小的Debug" class="headerlink" title="小小的Debug"></a>小小的Debug</h4><p>安装时，显示在resolveNewModule步骤耗时很久，不知道是卡住还是这个步骤本就耗费时间。<br>Google找到Hexo的官方说明文档(<a href="https://hexo.io/zh-cn/docs/">https://hexo.io/zh-cn/docs/</a>)，其中提到安装只需要几分钟，并且这个几分钟可能包含前述的Git和Node.js的准备。因此意识到安装出现问题，直接停下此次安装并重新运行命令。<br>出现问题的原因可能是安装的同时在下载一个较大的文件，无论是内存占用还是网络占用都达到一定程度，使得Hexo的安装受到影响。二次运行命令行时，下载已经结束，只用时51s就完成安装。<br>多翻了几个教程，很多教程都有提到新建文件夹Hexo，在这个目录下安装Hexo。因此卸载Hexo，在目标位置建立文件夹重装。卸载命令：  </p>
<pre><code>$ npm uninstall hexo-cli -g
</code></pre>
<p>这次安装同样比较顺利，很快就完成。<br>实际上，如果在安装前没有建立文件夹，只需在安装成功后建立一个新目录，后续步骤在这个空目录下进行即可。上述uninstall步骤是因为比较心急，直接推翻重来，但没有必要。</p>
<h2 id="GitHub-Pages"><a href="#GitHub-Pages" class="headerlink" title="GitHub Pages"></a>GitHub Pages</h2><h3 id="git初始配置"><a href="#git初始配置" class="headerlink" title="git初始配置"></a>git初始配置</h3><p>Git安装完成后确认是否完成基本部署，用户名和邮箱设置是否完成。  </p>
<pre><code>$ git config --global user.name &quot;YOUR NAME&quot;  #设置用户名称
$ git config --global user.email &quot;YOUR EMAIL&quot;  #设置邮箱地址
</code></pre>
<h3 id="生成SSH-key公钥"><a href="#生成SSH-key公钥" class="headerlink" title="生成SSH key公钥"></a>生成SSH key公钥</h3><p>查看当前用户的目录下是否存在.ssh目录，如果存在进入到此目录下检查是否存在id_rsa和id_rsa.pub两个文件，这两个文件分别对应的是公钥和私钥，如果存在直接跳过此步，否则输入下面的命令：  </p>
<pre><code>$ ssh-keygen -t rsa -C “your_github_email”
# -t type:指定你要生成的密钥类型
# -C commit:提供一个新的注释  
</code></pre>
<p>然后一路回车，直到生成一个矩形的图案为止。记下生成的这串字符，这就是后面需要给GitHub配置的公钥。</p>
<h3 id="创建GitHub账号"><a href="#创建GitHub账号" class="headerlink" title="创建GitHub账号"></a>创建GitHub账号</h3><p>打开官网用邮箱一步步注册即可，仅有的两个可能遇到的问题:</p>
<ul>
<li>没想好用户名</li>
<li>确认注册的邮件因为有链接可能会被当作垃圾邮件。</li>
</ul>
<h3 id="配置GitHub中的公钥"><a href="#配置GitHub中的公钥" class="headerlink" title="配置GitHub中的公钥"></a>配置GitHub中的公钥</h3><p>在GitHub账号设置中找到添加SSH key的地方，即<br>Settings -&gt; SSH and GPG keys -&gt; New SSH key<br>将前述步骤中生成的公钥贴在此处  </p>
<h3 id="创建仓库-repository"><a href="#创建仓库-repository" class="headerlink" title="创建仓库(repository)"></a>创建仓库(repository)</h3><p>单机右上角(用户头像旁边)的“+”号即可创建New repository，会出现如图所示界面。<br>Owner处为用户名，后面的Repository name需要严格按照username.github.io填写。这样才能保证生成的是GitHub Pages页面，而不是其它代码库。  </p>
<h3 id="GitHub-Pages-1"><a href="#GitHub-Pages-1" class="headerlink" title="GitHub Pages"></a>GitHub Pages</h3><p>创建成功后会自动进入该repository，进入setting找到Pages，进入后即可看到GitHub Pages界面。<br>这一步骤可能需要一些时间，耐心等待，一般几分钟就会显示站点发布成功。</p>
<h4 id="小小的debug"><a href="#小小的debug" class="headerlink" title="小小的debug"></a>小小的debug</h4><p>第一次走到这一步时，此处有一句提醒，由于该GitHub仓库是空的，所以无法创建GitHub Pages站点。解决方式： </p>
<ul>
<li>可自己创建一个README文件</li>
<li>粗暴删库重来，建库时选择生成默认README文件  </li>
</ul>
<h2 id="将Hexo部署到GitHub"><a href="#将Hexo部署到GitHub" class="headerlink" title="将Hexo部署到GitHub"></a>将Hexo部署到GitHub</h2><h3 id="安装hexo-deployer-git"><a href="#安装hexo-deployer-git" class="headerlink" title="安装hexo-deployer-git"></a>安装hexo-deployer-git</h3><p>在博客根目录下运行命令  </p>
<pre><code>$ npm install hexo-deployer-git –save
</code></pre>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>_config.yml是整个博客的配置文件，每项配置参数在Hexo官方文档可找到详细介绍。<br>使用git能将本地博客文件夹关联到GitHub的远程仓库，并把本地文件push到对应的仓库中。Hexo提供了一种更简便地方式，只需要在_config.yml中作相应的配置，通过命令行命令就可以很方便地把静态文件部署到对应的仓库中。<br>找到根目录中的_config.yml博客配置文件，在deployment配置项下设置如下参数：  </p>
<pre><code>deploy:  
    type: git  
    repo: git@github.com:yourname/yourname.github.io.git  
    branch: master  
</code></pre>
<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><pre><code>$ hexo generate #生成本地静态文件，可缩写为hexo g
$ hexo deploy   #部署，可缩写为hexo d
</code></pre>
<p>这时回到GitHub仓库, 可以看到网站的静态文件已经上传。</p>
<h4 id="小小的Debug-1"><a href="#小小的Debug-1" class="headerlink" title="小小的Debug"></a>小小的Debug</h4><p>部署没有报错，但网站没有更新<br>原因：GitHub Pages默认是从main生成页面，但本地设置部署参数是branch一项中填写的是master<br>Debug：修改该repository设置中pages的source一项或将前面提到的修改博客配置文件的branch参数为main</p>
<h3 id="一些有用的命令"><a href="#一些有用的命令" class="headerlink" title="一些有用的命令"></a>一些有用的命令</h3><pre><code>hexo clean = hexo c #清除本地缓存，也就是清除public/文件夹和db.json文件
hexo generate = hexo g #将souce文件夹下的Markdown和HTML文件解析到了public文件夹下，并生成了db.json文件
hexo server = hexo s #开启本地调试模式
hexo deploy = hexo d #将本地资源部署到GithubPages
</code></pre>
<h2 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h2><h3 id="选择主题"><a href="#选择主题" class="headerlink" title="选择主题"></a>选择主题</h3><p>Hexo的官网上即可找到许多可用主题，或搜索Hexo theme也可以找到。官网中列出的主题直达：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a><br>找主题除了符合自己的审美之外，也要注意该主题是否一直有人维护。较长时间无人维护的主题可能由于版本问题无法顺利安装使用。</p>
<h3 id="安装主题"><a href="#安装主题" class="headerlink" title="安装主题"></a>安装主题</h3><p>本博客选择的主题是Next，安装步骤如下：<br>将主题clone到theme文件夹下</p>
<pre><code>$ cd blog
$ git clone https://github.com/next-theme/hexo-theme-next themes/next
</code></pre>
<p>然后在hexo配置文件中修改themes为next</p>
<pre><code>themes: next
</code></pre>
<h3 id="一些小改动"><a href="#一些小改动" class="headerlink" title="一些小改动"></a>一些小改动</h3><p>根据next的说明文件，可以在该主题的配置文件中对细节进行修改。<br>对博客名、描述以及作者等的修改在根目录的配置文件中进行。</p>
]]></content>
      <categories>
        <category>Blog</category>
        <category>Building</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Github</tag>
        <tag>Blog</tag>
      </tags>
  </entry>
  <entry>
    <title>blastp的本地化使用</title>
    <url>/2021/09/16/blastp/</url>
    <content><![CDATA[<center>blastp在Windows系统电脑上的本地使用</center>
<span id="more"></span>

<h2 id="下载blast到本地"><a href="#下载blast到本地" class="headerlink" title="下载blast到本地"></a>下载blast到本地</h2><p>在NCBI官网找到blast工具即可找到下载链接，根据提示一步步完成下载即可。<br>官网下载链接：<a href="https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=Download">blast tools</a><br>网站打开速度较慢，挂梯可能会好一点。</p>
<h2 id="本地使用"><a href="#本地使用" class="headerlink" title="本地使用"></a>本地使用</h2><h3 id="建库"><a href="#建库" class="headerlink" title="建库"></a>建库</h3><p>从uniprot下载所需参考蛋白质组的fast.a文件作为建库文件此处以人类蛋白质组为例  </p>
<pre><code>$ makeblastdb -in uniprot-proteome%3AUP000005640.fasta -dbtype prot -parse_seqids -hash_index -out human
# 在blast-2.6.0/bin文件夹下运行该命令或在makeblastdb前加上该程序所在的路径

# 参数说明
# -in 所需建库的参考蛋白质组
# -out 输出的库名
# -dbtype 蛋白质组用prot，核酸组用nucl
# parse_seqids =&gt; Parse Seq-ids in FASTA input
# -hash_index =&gt; Create index of sequence hash values
</code></pre>
<h3 id="搜库比对"><a href="#搜库比对" class="headerlink" title="搜库比对"></a>搜库比对</h3><p>将query序列比对到参考序列。此处用小鼠蛋白质组和人蛋白质组进行比对，运行如下命令：</p>
<pre><code>$ blastp.exe -query uniprot-proteome%3AUP000000589.fasta -db human -evalue 1e-3 -out blast.xml -outfmt &quot;5&quot; -num_alignments 10 -num_threads 2
#在blast-2.6.0/bin文件夹下运行该命令或在blastp.exe前加上该程序所在的路径

# 参数说明
# -query 输入文件名，也就是需要比对的序列文件
# -db 格式化后的数据库名称
# -evalue 设定输出结果中的e-value阈值
# -out 输出文件名
# -num_alignments 输出比对上的序列的最大值条目数
# -num_threads 线程数
# 此外还有：
# -num_descriptions 对比对上序列的描述信息，一般跟tabular格式连用
# -outfmt
#   0 = pairwise,
#   1 = query-anchored showing identities,
#   2 = query-anchored no identities,
#   3 = flat query-anchored, show identities,
#   4 = flat query-anchored, no identities,
#   5 = XML Blast output,
#   6 = tabular,
#   7 = tabular with comment lines,
#   8 = Text ASN.1,
#   9 = Binary ASN.1
#  10 = Comma-separated values
</code></pre>
<h3 id="提取搜库结果中的信息"><a href="#提取搜库结果中的信息" class="headerlink" title="提取搜库结果中的信息"></a>提取搜库结果中的信息</h3><h2 id="xml文件所含的信息"><a href="#xml文件所含的信息" class="headerlink" title="xml文件所含的信息"></a>xml文件所含的信息</h2><p>使用outfmt 5参数的话，会产生一个xml格式的文件，对比信息很完整。一个序列的完整比对信息如下所示：</p>
<pre><code>&lt;Iteration&gt;
&lt;Iteration_iter-num&gt;1&lt;/Iteration_iter-num&gt;
&lt;Iteration_query-ID&gt;Query_1&lt;/Iteration_query-ID&gt;
&lt;Iteration_query-def&gt;sp|Q62302|TX261_MOUSE Protein TEX261 OS=Mus musculus OX=10090 GN=Tex261 PE=2 SV=1&lt;/Iteration_query-def&gt;
&lt;Iteration_query-len&gt;196&lt;/Iteration_query-len&gt;
&lt;Iteration_hits&gt;
&lt;Hit&gt;
&lt;Hit_num&gt;1&lt;/Hit_num&gt;
&lt;Hit_id&gt;sp|Q6UWH6|TX261_HUMAN&lt;/Hit_id&gt;
&lt;Hit_def&gt;Protein TEX261 OS=Homo sapiens OX=9606 GN=TEX261 PE=2 SV=1&lt;/Hit_def&gt;
&lt;Hit_accession&gt;Q6UWH6&lt;/Hit_accession&gt;
&lt;Hit_len&gt;196&lt;/Hit_len&gt;
&lt;Hit_hsps&gt;
  &lt;Hsp&gt;
    &lt;Hsp_num&gt;1&lt;/Hsp_num&gt;
    &lt;Hsp_bit-score&gt;391.734&lt;/Hsp_bit-score&gt;
    &lt;Hsp_score&gt;1005&lt;/Hsp_score&gt;
    &lt;Hsp_evalue&gt;8.09539e-141&lt;/Hsp_evalue&gt;
    &lt;Hsp_query-from&gt;1&lt;/Hsp_query-from&gt;
    &lt;Hsp_query-to&gt;196&lt;/Hsp_query-to&gt;
    &lt;Hsp_hit-from&gt;1&lt;/Hsp_hit-from&gt;
    &lt;Hsp_hit-to&gt;196&lt;/Hsp_hit-to&gt;
    &lt;Hsp_query-frame&gt;0&lt;/Hsp_query-frame&gt;
    &lt;Hsp_hit-frame&gt;0&lt;/Hsp_hit-frame&gt;
    &lt;Hsp_identity&gt;195&lt;/Hsp_identity&gt;
    &lt;Hsp_positive&gt;196&lt;/Hsp_positive&gt;
    &lt;Hsp_gaps&gt;0&lt;/Hsp_gaps&gt;
    &lt;Hsp_align-len&gt;196&lt;/Hsp_align-len&gt;
    &lt;Hsp_qseq&gt;MWFMYVLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIWFSTAVLIGLYVFERFPTSMIGVGLFTNLVYFGLLQTFPFIMLTSPNFILSCGLVVVNHYLAFQFFAEEYYPFSEVLAYFTFCLWIIPFAFFVSLSAGENVLPSTMQPGDDVVSNYFTKGKRGKRLGILVVFSFIKEAILPSRQKIY&lt;/Hsp_qseq&gt;
    &lt;Hsp_hseq&gt;MWFMYLLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIWFSTAVLIGLYVFERFPTSMIGVGLFTNLVYFGLLQTFPFIMLTSPNFILSCGLVVVNHYLAFQFFAEEYYPFSEVLAYFTFCLWIIPFAFFVSLSAGENVLPSTMQPGDDVVSNYFTKGKRGKRLGILVVFSFIKEAILPSRQKIY&lt;/Hsp_hseq&gt;
    &lt;Hsp_midline&gt;MWFMY+LSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIWFSTAVLIGLYVFERFPTSMIGVGLFTNLVYFGLLQTFPFIMLTSPNFILSCGLVVVNHYLAFQFFAEEYYPFSEVLAYFTFCLWIIPFAFFVSLSAGENVLPSTMQPGDDVVSNYFTKGKRGKRLGILVVFSFIKEAILPSRQKIY&lt;/Hsp_midline&gt;
  &lt;/Hsp&gt;
&lt;/Hit_hsps&gt;
&lt;/Hit&gt;
&lt;Hit&gt;
&lt;Hit_num&gt;2&lt;/Hit_num&gt;
&lt;Hit_id&gt;tr|U3KQ87|U3KQ87_HUMAN&lt;/Hit_id&gt;
&lt;Hit_def&gt;Uncharacterized protein OS=Homo sapiens OX=9606 PE=4 SV=1&lt;/Hit_def&gt;
&lt;Hit_accession&gt;U3KQ87&lt;/Hit_accession&gt;
&lt;Hit_len&gt;197&lt;/Hit_len&gt;
&lt;Hit_hsps&gt;
  &lt;Hsp&gt;
    &lt;Hsp_num&gt;1&lt;/Hsp_num&gt;
    &lt;Hsp_bit-score&gt;312.768&lt;/Hsp_bit-score&gt;
    &lt;Hsp_score&gt;800&lt;/Hsp_score&gt;
    &lt;Hsp_evalue&gt;1.35723e-109&lt;/Hsp_evalue&gt;
    &lt;Hsp_query-from&gt;1&lt;/Hsp_query-from&gt;
    &lt;Hsp_query-to&gt;158&lt;/Hsp_query-to&gt;
    &lt;Hsp_hit-from&gt;1&lt;/Hsp_hit-from&gt;
    &lt;Hsp_hit-to&gt;158&lt;/Hsp_hit-to&gt;
    &lt;Hsp_query-frame&gt;0&lt;/Hsp_query-frame&gt;
    &lt;Hsp_hit-frame&gt;0&lt;/Hsp_hit-frame&gt;
    &lt;Hsp_identity&gt;157&lt;/Hsp_identity&gt;
    &lt;Hsp_positive&gt;158&lt;/Hsp_positive&gt;
    &lt;Hsp_gaps&gt;0&lt;/Hsp_gaps&gt;
    &lt;Hsp_align-len&gt;158&lt;/Hsp_align-len&gt;
    &lt;Hsp_qseq&gt;MWFMYVLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIWFSTAVLIGLYVFERFPTSMIGVGLFTNLVYFGLLQTFPFIMLTSPNFILSCGLVVVNHYLAFQFFAEEYYPFSEVLAYFTFCLWIIPFAFFVSLSAGENVLPSTMQPG&lt;/Hsp_qseq&gt;
    &lt;Hsp_hseq&gt;MWFMYLLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIWFSTAVLIGLYVFERFPTSMIGVGLFTNLVYFGLLQTFPFIMLTSPNFILSCGLVVVNHYLAFQFFAEEYYPFSEVLAYFTFCLWIIPFAFFVSLSAGENVLPSTMQPG&lt;/Hsp_hseq&gt;
    &lt;Hsp_midline&gt;MWFMY+LSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIWFSTAVLIGLYVFERFPTSMIGVGLFTNLVYFGLLQTFPFIMLTSPNFILSCGLVVVNHYLAFQFFAEEYYPFSEVLAYFTFCLWIIPFAFFVSLSAGENVLPSTMQPG&lt;/Hsp_midline&gt;
  &lt;/Hsp&gt;
&lt;/Hit_hsps&gt;
&lt;/Hit&gt;
&lt;Hit&gt;
&lt;Hit_num&gt;3&lt;/Hit_num&gt;
&lt;Hit_id&gt;tr|F8WAR8|F8WAR8_HUMAN&lt;/Hit_id&gt;
&lt;Hit_def&gt;Protein TEX261 OS=Homo sapiens OX=9606 GN=TEX261 PE=4 SV=1&lt;/Hit_def&gt;
&lt;Hit_accession&gt;F8WAR8&lt;/Hit_accession&gt;
&lt;Hit_len&gt;51&lt;/Hit_len&gt;
&lt;Hit_hsps&gt;
  &lt;Hsp&gt;
    &lt;Hsp_num&gt;1&lt;/Hsp_num&gt;
    &lt;Hsp_bit-score&gt;98.5969&lt;/Hsp_bit-score&gt;
    &lt;Hsp_score&gt;244&lt;/Hsp_score&gt;
    &lt;Hsp_evalue&gt;4.07837e-27&lt;/Hsp_evalue&gt;
    &lt;Hsp_query-from&gt;1&lt;/Hsp_query-from&gt;
    &lt;Hsp_query-to&gt;50&lt;/Hsp_query-to&gt;
    &lt;Hsp_hit-from&gt;1&lt;/Hsp_hit-from&gt;
    &lt;Hsp_hit-to&gt;50&lt;/Hsp_hit-to&gt;
    &lt;Hsp_query-frame&gt;0&lt;/Hsp_query-frame&gt;
    &lt;Hsp_hit-frame&gt;0&lt;/Hsp_hit-frame&gt;
    &lt;Hsp_identity&gt;49&lt;/Hsp_identity&gt;
    &lt;Hsp_positive&gt;50&lt;/Hsp_positive&gt;
    &lt;Hsp_gaps&gt;0&lt;/Hsp_gaps&gt;
    &lt;Hsp_align-len&gt;50&lt;/Hsp_align-len&gt;
    &lt;Hsp_qseq&gt;MWFMYVLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIW&lt;/Hsp_qseq&gt;
    &lt;Hsp_hseq&gt;MWFMYLLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIW&lt;/Hsp_hseq&gt;
    &lt;Hsp_midline&gt;MWFMY+LSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIW&lt;/Hsp_midline&gt;
  &lt;/Hsp&gt;
&lt;/Hit_hsps&gt;
&lt;/Hit&gt;
&lt;Hit&gt;
&lt;Hit_num&gt;4&lt;/Hit_num&gt;
&lt;Hit_id&gt;tr|U3KQC7|U3KQC7_HUMAN&lt;/Hit_id&gt;
&lt;Hit_def&gt;Uncharacterized protein (Fragment) OS=Homo sapiens OX=9606 PE=4 SV=1&lt;/Hit_def&gt;
&lt;Hit_accession&gt;U3KQC7&lt;/Hit_accession&gt;
&lt;Hit_len&gt;49&lt;/Hit_len&gt;
&lt;Hit_hsps&gt;
  &lt;Hsp&gt;
    &lt;Hsp_num&gt;1&lt;/Hsp_num&gt;
    &lt;Hsp_bit-score&gt;91.2781&lt;/Hsp_bit-score&gt;
    &lt;Hsp_score&gt;225&lt;/Hsp_score&gt;
    &lt;Hsp_evalue&gt;2.69841e-24&lt;/Hsp_evalue&gt;
    &lt;Hsp_query-from&gt;4&lt;/Hsp_query-from&gt;
    &lt;Hsp_query-to&gt;50&lt;/Hsp_query-to&gt;
    &lt;Hsp_hit-from&gt;2&lt;/Hsp_hit-from&gt;
    &lt;Hsp_hit-to&gt;48&lt;/Hsp_hit-to&gt;
    &lt;Hsp_query-frame&gt;0&lt;/Hsp_query-frame&gt;
    &lt;Hsp_hit-frame&gt;0&lt;/Hsp_hit-frame&gt;
    &lt;Hsp_identity&gt;46&lt;/Hsp_identity&gt;
    &lt;Hsp_positive&gt;47&lt;/Hsp_positive&gt;
    &lt;Hsp_gaps&gt;0&lt;/Hsp_gaps&gt;
    &lt;Hsp_align-len&gt;47&lt;/Hsp_align-len&gt;
    &lt;Hsp_qseq&gt;MYVLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIW&lt;/Hsp_qseq&gt;
    &lt;Hsp_hseq&gt;MYLLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIW&lt;/Hsp_hseq&gt;
    &lt;Hsp_midline&gt;MY+LSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIW&lt;/Hsp_midline&gt;
  &lt;/Hsp&gt;
&lt;/Hit_hsps&gt;
&lt;/Hit&gt;
&lt;/Iteration_hits&gt;
&lt;Iteration_stat&gt;
  &lt;Statistics&gt;
    &lt;Statistics_db-num&gt;95943&lt;/Statistics_db-num&gt;
    &lt;Statistics_db-len&gt;38082498&lt;/Statistics_db-len&gt;
    &lt;Statistics_hsp-len&gt;101&lt;/Statistics_hsp-len&gt;
    &lt;Statistics_eff-space&gt;2697264225&lt;/Statistics_eff-space&gt;
    &lt;Statistics_kappa&gt;0.041&lt;/Statistics_kappa&gt;
    &lt;Statistics_lambda&gt;0.267&lt;/Statistics_lambda&gt;
    &lt;Statistics_entropy&gt;0.14&lt;/Statistics_entropy&gt;
  &lt;/Statistics&gt;
&lt;/Iteration_stat&gt;
&lt;/Iteration&gt;
</code></pre>
<h3 id="提取信息"><a href="#提取信息" class="headerlink" title="提取信息"></a>提取信息</h3><p>观察序列信息的各种标识，可从中提取有用的信息。下面是以julia语言写的一个简单粗暴提取比对上的两个蛋白(Accession)以及打分信息的脚本。</p>
<pre><code># Julia language
function main()
    ioBlast = open(&quot;blast.xml&quot;, &quot;r&quot;) 
    # 读BLAST结果
    ioBPout = open(&quot;blastresult.txt&quot;, &quot;w&quot;) 
    # 将提取的信息写入该文件
    # 自行选择方便后续步骤的文件格式
    
    write(ioBPout, &quot;Mouse\tHuman\tHsp_bit-score\thspscore\t&quot;) # 信息表头

    global Mouse_P, Human_P, bitscore, hspscore 
    # 声明变量为global，便于后续的步骤

    while !eof(ioBlast)
        # 按行读文件，若有所需信息则提取，没有则继续读取下一行
        line = readline(ioBlast)
        if occursin(r&quot;&lt;Iteration_query-def&gt;&quot;, line)
            (a, Mouse_P, c) = split(line, &quot;|&quot;)
        end
        if occursin(r&quot;&lt;Hit_id&gt;&quot;, line)
            (a, Human_P, c) = split(line, &quot;|&quot;)
        end
        if occursin(r&quot;&lt;Hsp_bit-score&gt;&quot;, line)
            (a, temps) = split(line, &quot;&gt;&quot;)
            (bitscore, c) = split(temps, &quot;&lt;&quot;)
        end
        if occursin(r&quot;&lt;Hsp_score&gt;&quot;, line)
            (a, temps) = split(line, &quot;&gt;&quot;)
            (hspscore, c) = split(temps, &quot;&lt;&quot;)
        end
        if occursin(r&quot;&lt;/Hit&gt;&quot;, line)
            write(ioBPout, Mouse_P, &quot;\t&quot;, Human_P, &quot;\t&quot;, bitscore, &quot;\t&quot;, hspscore, &quot;\n&quot;)
        end
    end

    close(ioBlast)
    close(ioBPout)            
end

main() # 运行上述函数
</code></pre>
<h3 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h3><ol>
<li><a href="https://www.bioinfo-scrounger.com/archives/77/">BLAST本地化使用</a></li>
<li><a href="https://www.bioinfo-scrounger.com/archives/82/">Blast+ xml格式解读</a>  </li>
</ol>
]]></content>
      <categories>
        <category>Tools</category>
        <category>BLAST</category>
      </categories>
      <tags>
        <tag>BLAST</tag>
      </tags>
  </entry>
  <entry>
    <title>Mastodon 建站笔记(缓慢搭建中，目前仅到安装 docker)</title>
    <url>/2022/03/02/buildmastodon/</url>
    <content><![CDATA[<center> mastodon 建站笔记：慢慢来，6 月之前搞完就行；不要怕，不行就重启试试 </center>
<span id="more"></span>

<h2 id="一点说明"><a href="#一点说明" class="headerlink" title="一点说明"></a>一点说明</h2><p>本文所记录的搭建非常缓慢，开始于二月，但给自己设定的 DDL 在六月。搭建过程完全碎片化，每次推进都基于“这会儿没什么事情不如搞一搞建站”，且超过一小时就会先放着下次再说，非常随性随意。每一步完成于哪一天、大概耗时都有记录，给想搭建却又嫌麻烦、觉得需要特意安排时间的朋友提供一个佛系搭建参考。  </p>
<h2 id="参考与致谢"><a href="#参考与致谢" class="headerlink" title="参考与致谢"></a>参考与致谢</h2><p>参考蓝盒子站长的<a href="https://pullopen.github.io/%E5%9F%BA%E7%A1%80%E6%90%AD%E5%BB%BA/2020/10/19/Mastodon-on-Docker.html">利用 docker 搭建 Mastodon 实例</a>，并结合塔塔的<a href="https://mantyke.icu/2021/mastodon-bulid/">小球飞象建站笔记</a> 和此方的 <a href="https://tech.konata.co/2022-02-10-build-a-mastodon/">Mastodon 建站笔记</a>。  </p>
<p>感谢嘎嘎、塔塔、此方和其他写下详细教程和笔记的朋友！因为你们和你们的教程，我这种没有参考不敢做事的人才能一点点把实例搭建起来。<br>特别感谢塔塔，给我每完成一步的嘟嘟点星星，给予我很大鼓励！  </p>
<h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><p>前期准备主要是花钱，大多数运营商都支持 Visa、MasterCard 或 PayPal，godaddy 支持支付宝付款。<br>为能有更多选择，个人建议开通 PayPal，比办信用卡方便一些。本文中的所有支付就是通过 PayPal 完成。如使用 PayPal 付款，建议付款时直接使用目标货币，而不使用 PayPal 提供的转换为人民币付款。这种情况下付款使用的是银行汇率，会比 PayPal 划算。  </p>
<h3 id="域名"><a href="#域名" class="headerlink" title="域名"></a>域名</h3><p>常用的域名提供商很多，比如 <a href="https://www.namecheap.com/">NameCheap</a>，<a href="https://sg.godaddy.com/">godaddy</a> 和 <a href="https://www.dynadot.com/">dynadot</a>。可参考o3o站长给出的<a href="https://www.notion.so/c66e3332f4824f71b9d7d1dc8db410c7">域名选购指南</a>。<br>本站根据蓝盒子站长的推荐，在 NameCheap 购买域名。由于之前给博客换域名已经在 NameCheap 买过一次，而且很早就想好要买什么域名，所以这一步成为这个跨越几个月的搭建过程中最简单、最快速的一步。  </p>
<p>该步骤完成于 2022.02.17。约耗时 15 分钟，主要在犹豫到底要不要这天买，实际操作只用掉两三分钟。以及早知道我这么快就要自建站，博客就换个域名了！两年后我博客必换域名！</p>
<h3 id="邮件服务"><a href="#邮件服务" class="headerlink" title="邮件服务"></a>邮件服务</h3><p>使用 Zoho Mail 提供的 Business Mail 服务中的 Forever Free Plan。<br>由于本人需要很详细的操作步骤才敢进行下一步，这里找了个注册 Zoho Mail 的详细教程 —— <a href="https://www.dreambuildinglab.com/website-construction/email/how-to-register-free-zoho-business-email.html">注册zoho免费企业邮箱</a>。这个教程虽然详细，但稍微有点过时，有些操作的名称略有更改。如有需要，可再找其它教程参考。  </p>
<p>该步骤完成于 2022.02.21。约耗时 40 分钟，因为一些步骤没有明确的参考不太敢试，必须找到别人这一步怎么做才动手。但实际上没关系，大胆试，不行重来嘛！  </p>
<h3 id="购买VPS"><a href="#购买VPS" class="headerlink" title="购买VPS"></a>购买VPS</h3><p>选择 <a href="https://contabo.com/en/">Contabo</a> 购买 VPS，在购买前将价格修改为欧元，选择5欧套餐，德国服务器，一次性购买 12 个月，其它选项全部默认。<br>这里塔塔提醒<a href="https://mantyke.icu/2021/mastodon-bulid/#%E8%B4%AD%E4%B9%B0vps"> Contabo 审核严格</a>，最好真实 IP 购买，填写信息时不要太扯，不然会被要求提供身份证明。但我就是那个认真填写还被要求提供护照的倒霉蛋。由于目前和德国有 7 个小时时差，上午提供护照信息后，一直到下午四点多才收到确认邮件。  </p>
<p>该步骤完成于 2022.03.02。约耗时 15 分钟加 19 小时，15 分钟是实际需要操作的时间，包括提供护照信息；19 小时是由于买服务器时护照不在手边，第二天上午才回复，下午收到确认。  </p>
<h2 id="建站"><a href="#建站" class="headerlink" title="建站"></a>建站</h2><h3 id="配置系统"><a href="#配置系统" class="headerlink" title="配置系统"></a>配置系统</h3><p>这一部分参考<a href="https://pullopen.github.io/%E5%9F%BA%E7%A1%80%E6%90%AD%E5%BB%BA/2020/10/19/Mastodon-on-Docker.html">蓝盒子站长教程</a>。  </p>
<ul>
<li><p>配置 ssh-key<br>首先查看电脑当前用户的目录下是否存在.ssh目录，以及目录中是否存在<code>id_rsa</code>和<code>id_rsa.pub</code>两个文件。如果存在，公钥即为<code>id_rsa.pub</code>中的内容。如果不存在，则输入命令：  </p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -C “your_email”</span><br></pre></td></tr></table></figure>
<p>一路回车，直到生成一个矩形的图案为止，生成的这串字符就是后面需要的公钥。  </p>
<p>接下来的步骤全部按照蓝盒子站长的教程进行，但我遇到了一个愚蠢的问题，不会保存 nano 编辑的内容并退出。即使编辑器下方有两行提醒，也没能正确保存文件。万一有朋友和我一样，可参考以下保存并退出的方法：  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ^ 为键盘上的 Ctrl 键，以下方法直接使用 Ctrl 代替</span><br><span class="line"># 退出，并根据提示保存</span><br><span class="line">Ctrl + X 退出，按 y 选择保存，提示 file name to write，利用上下左右键选择要保存到的文件，回车保存</span><br><span class="line"># 退出，并保存</span><br><span class="line">Ctrl + X 退出，按 y 选择保存，回车</span><br><span class="line"># 先保存，后退出</span><br><span class="line">Ctrl + O 并回车保存，Ctrl + X 退出</span><br></pre></td></tr></table></figure></li>
<li><p>安装常用命令和配置防火墙<br>直接照抄蓝盒子站长给的命令，都非常顺利。  </p>
</li>
</ul>
<p>该步骤完成于 2022.03.03。约耗时 55 分钟，主要由于不会保存 nano 编辑的内容，根据各种教程也总是保存失败。中途一度试图换回之前常用的 vim，但事实证明两年没用就会忘记一切。如果能顺利保存，这一步十分钟以内就可以完成。  </p>
<ul>
<li>tips<br>虽然上次建站配置好了服务器端的公钥，但这次登录时，MobaXterm 一直返回错误信息：  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  Disconnected: No supported authentication methods available (server sent: publickey)  </span><br><span class="line">  ```  </span><br><span class="line">  原因是服务器已经关闭账户密码登录，但使用 MobaXterm 登录时没有勾选 `Use private key` 并指定私钥文件。具体步骤为 `Session -&gt; SSH -&gt; Use private key and specify a private key for passwordless login`。  </span><br><span class="line">  设置完成后即可顺利登录。  </span><br><span class="line"></span><br><span class="line">### 安装 docker 和 docker-compose</span><br><span class="line">根据蓝盒子站长的教程，使用官方提供的一键脚本安装 docker。</span><br></pre></td></tr></table></figure>
<h1 id="代码来自蓝盒子站长教程"><a href="#代码来自蓝盒子站长教程" class="headerlink" title="代码来自蓝盒子站长教程"></a>代码来自蓝盒子站长教程</h1>bash &lt;(curl -L <a href="https://get.docker.com/">https://get.docker.com/</a>)<br>sudo curl -L “<a href="https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$">https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$</a>(uname -s)-$(uname -m)” -o /usr/local/bin/docker-compose<br>sudo chmod +x /usr/local/bin/docker-compose<br>```</li>
</ul>
<p>该步骤完成于 2022.03.13。约耗时 15 分钟，包括一开始登录不上服务器而查找原因的时间，实际操作时间约 3 分钟。这一步骤完成后可以通过命令 <code>docker-compose -h</code> 检查 docker 是否真的安装成功。  </p>
]]></content>
      <categories>
        <category>Mastodon</category>
        <category>Build</category>
      </categories>
      <tags>
        <tag>Mastodon</tag>
      </tags>
  </entry>
  <entry>
    <title>在文章中插入图片的各种方式</title>
    <url>/2021/10/19/imginblog/</url>
    <content><![CDATA[<center>终于还是没能避免想要在文章中用到图片，所以有了本文记录在Hexo博客中插入图片的各种方式</center>  
<span id="more"></span>  

<h2 id="本地引用"><a href="#本地引用" class="headerlink" title="本地引用"></a>本地引用</h2><h3 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h3><p>安装插件<code>hexo-asset-image</code></p>
<pre><code>npm install hexo-asset-image --save
</code></pre>
<p>安装成功后，打开<code>/node_modules/hexo-asset-image/index.js</code>，替换成下列内容：</p>
<pre><code>&#39;use strict&#39;;
var cheerio = require(&#39;cheerio&#39;);

// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-string
function getPosition(str, m, i) &#123;
return str.split(m, i).join(m).length;
&#125;

var version = String(hexo.version).split(&#39;.&#39;);
hexo.extend.filter.register(&#39;after_post_render&#39;, function(data)&#123;
var config = hexo.config;
if(config.post_asset_folder)&#123;
    var link = data.permalink;
if(version.length &gt; 0 &amp;&amp; Number(version[0]) == 3)
    var beginPos = getPosition(link, &#39;/&#39;, 1) + 1;
else
    var beginPos = getPosition(link, &#39;/&#39;, 3) + 1;
// In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.
var endPos = link.lastIndexOf(&#39;/&#39;) + 1;
    link = link.substring(beginPos, endPos);
var toprocess = [&#39;excerpt&#39;, &#39;more&#39;, &#39;content&#39;];
for(var i = 0; i &lt; toprocess.length; i++)&#123;
var key = toprocess[i];

var $ = cheerio.load(data[key], &#123;
    ignoreWhitespace: false,
    xmlMode: false,
    lowerCaseTags: false,
    decodeEntities: false
&#125;);

$(&#39;img&#39;).each(function()&#123;
if ($(this).attr(&#39;src&#39;))&#123;
// For windows style path, we replace &#39;\&#39; to &#39;/&#39;.
var src = $(this).attr(&#39;src&#39;).replace(&#39;\\&#39;, &#39;/&#39;);
if(!/http[s]*.*|\/\/.*/.test(src) &amp;&amp;
    !/^\s*\//.test(src)) &#123;
    // For &quot;about&quot; page, the first part of &quot;src&quot; can&#39;t be removed.
    // In addition, to support multi-level local directory.
    var linkArray = link.split(&#39;/&#39;).filter(function(elem)&#123;
    return elem != &#39;&#39;;
    &#125;);
    var srcArray = src.split(&#39;/&#39;).filter(function(elem)&#123;
    return elem != &#39;&#39; &amp;&amp; elem != &#39;.&#39;;
    &#125;);
    if(srcArray.length &gt; 1)
    srcArray.shift();
    src = srcArray.join(&#39;/&#39;);
    $(this).attr(&#39;src&#39;, config.root + link + src);
    console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);
&#125;
&#125;else&#123;
console.info&amp;&amp;console.info(&quot;no src attr, skipped...&quot;);
console.info&amp;&amp;console.info($(this));
    &#125;
&#125;);
data[key] = $.html();
    &#125;
&#125;
&#125;);
</code></pre>
<h3 id="绝对路径"><a href="#绝对路径" class="headerlink" title="绝对路径"></a>绝对路径</h3><p>当整个博客图片内容较少时，可将所有的图片都放在<code>source/images</code>文件夹下，通过<code>markdown</code>语法访问。  </p>
<pre><code>![](/images/img1.png)
</code></pre>
<p>对于图片较少切命名清晰的情况，这种方式存放图片足够。</p>
<h3 id="相对路径"><a href="#相对路径" class="headerlink" title="相对路径"></a>相对路径</h3><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>除了将图片存放在<code>source/images</code>文件夹下，还可以将图片存放在文章自己的目录中。文章目录可通过修改配置文件生成：  </p>
<pre><code>post_asset_folder: true  
</code></pre>
<p>将配置文件中<code>post_asset_folder</code>修改为<code>true</code>后，执行命令</p>
<pre><code>hexo new post newblog
</code></pre>
<p>会在<code>source/_posts</code>生成<code>newblog.md</code>和同名文件夹<code>newblog</code>。将图片存在该同名文件夹中，即可通过相对路径的方式在文章中添加图片。</p>
<pre><code>![](img.png)
</code></pre>
<p>这一方法能够在文章中显示图片，但无法在首页正常显示图片，如需在首页显示图片可使用如下方式：</p>
<pre><code>&#123;% asset_img img.png This is an image %&#125;
</code></pre>
<p>当图片内容较多，使用相对路径存放图片的方式更易于整理。</p>
<h4 id="小提示"><a href="#小提示" class="headerlink" title="小提示"></a>小提示</h4><p>如遇到修改配置文件后运行<code>hexo new newblog</code>命令无法正常建立一个同名文件夹，可以手动在<code>_POST</code>目录下建立一个同名文件夹，仍能够达到同样的效果。<br>实际上，md文件也可以手动新建。根据使用者的习惯，怎么新建md文件和同名文件夹都是可以的。<br>平时写文章不常用到图片，也可以使用手动建立同名文件夹的方式。  </p>
<h2 id="CDN引用"><a href="#CDN引用" class="headerlink" title="CDN引用"></a>CDN引用</h2><p>将图片上传到一些CDN服务中并使用对应的url地址引用图片也是一个很好的方式。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="https://yanyinhong.github.io/2017/05/02/How-to-insert-image-in-hexo-post/">Hexo博客搭建之在文章中插入图片</a><br>[2] <a href="https://fuhailin.github.io/Hexo-images/">在Hexo博客中插入图片的各种方式</a><br>[3] <a href="https://www.cxyzjd.com/article/m0_43401436/107191688">hexo博客中插入图片失败——解决思路及个人最终解决办法</a><br>[4] <a href="http://sdman.tech/2019/07/23/%E8%A7%A3%E5%86%B3Hexo%E6%A1%86%E6%9E%B6%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%87%E4%B8%8D%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98/">解决 Hexo 框架博客图片不显示的问题</a></p>
]]></content>
      <categories>
        <category>Blog</category>
        <category>Writing</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Blog</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Computational Deconvolution for More Precise Biological Data</title>
    <url>/2021/12/08/deconmixeddata/</url>
    <content><![CDATA[<center> 文献阅读：解卷积可从混合的生物学数据中解得各细胞类型比例，或估计各细胞类型的表达谱，为研究提供更准确的样本数据 </center>
<span id="more"></span>

<h2 id="Deconvolution"><a href="#Deconvolution" class="headerlink" title="Deconvolution"></a>Deconvolution</h2><p><strong>Deconvolution</strong> 译作反卷积或解卷积。解卷积是一种基于算法的过程，用于反转卷积对记录数据的影响。<br>生物学数据，如 DNA expression、RNA sequencing、Protein expression 等，很难真正得到来自特定组织的“纯数据”。如血液中含有来自不同组织的细胞、外泌体等，由此得来的生物学数据将是不同类型细胞的混合数据。这时就需要通过解卷积，从混合的生物数据中解得不同类型细胞的比例、表达谱。  </p>
<h2 id="基本模型"><a href="#基本模型" class="headerlink" title="基本模型"></a>基本模型</h2><p>测得的数据为不同类型细胞按照一定比例混合在一起的结果。  </p>
<ul>
<li>测得的表达矩阵为 <em>X</em>，则 x<sub>ij</sub> 表示 gene<sub>i</sub> 在 sample<sub>j</sub> 中的表达量或表达强度  </li>
<li>比例矩阵为 <em>R</em>，则 r<sub>kj</sub> 表示 k 类细胞在 sample<sub>j</sub> 中所占比例  </li>
<li>各细胞真实表达谱组成的矩阵为 <em>S</em>，则 s<sub>ik</sub> 表示表示 gene<sub>i</sub> 在 k 类细胞中的表达量或表达强度  </li>
</ul>
<p><img src="/2021/12/08/deconmixeddata/decon.png">  </p>
<h2 id="解卷积算法"><a href="#解卷积算法" class="headerlink" title="解卷积算法"></a>解卷积算法</h2><p>针对不同情况有不同的算法，根据项目中的先验知识选择合适的解卷积方法以达到最佳效果。<br>生物数据解卷积分为完全解卷积和不完全解卷积。  </p>
<ul>
<li><strong>完全解卷积</strong>：指混合细胞类型数目、比例和各细胞表达谱未知，仅依赖混合表达数据将它们解出来，即已知混合表达矩阵 <em>X</em>，解比例矩阵 <em>R</em> 和各细胞表达矩阵 <em>S</em>。完全解卷积的完全指细胞表达谱和比例都在算法中一次性解得。  </li>
<li><strong>不完全解卷积</strong>：指已知混合表达谱、细胞类型数目、比例，解各细胞表达谱，即已知比例矩阵 <em>R</em> 和混合表达矩阵 <em>X</em>，解矩阵各细胞表达矩阵 <em>S</em>。不完全是相对于完全解卷积而言，仅解得各细胞表达谱。  </li>
</ul>
<h3 id="完全解卷积"><a href="#完全解卷积" class="headerlink" title="完全解卷积"></a>完全解卷积</h3><h4 id="LinSeed"><a href="#LinSeed" class="headerlink" title="LinSeed"></a><a href="https://doi.org/10.1038/s41467-019-09990-5">LinSeed</a></h4><p>通过计算共线性网络 (Collinearity Network) 得到各类型细胞的 markers，利用 markers 对混合数据进行完全解卷积，同时得到各组分的比例和表达谱。<br><img src="/2021/12/08/deconmixeddata/LinSeed.jpg"></p>
<p><strong>Code availability:</strong>   </p>
<ul>
<li>R  </li>
<li><a href="https://github.com/ctlab/linseed">https://github.com/ctlab/linseed</a>  </li>
</ul>
<h4 id="Deblender"><a href="#Deblender" class="headerlink" title="Deblender"></a><a href="https://doi.org/10.1186/s12859-018-2442-5">Deblender</a></h4><p>Deblender 是一个灵活的完全去卷积工具。基于用户对已知标记基因列表和细胞/组织组成信息的访问 (access)，以半/无监督模式运行。在没有先验知识的情况下，全局基因表达的变异性被用于混合数据的聚类，以聚类集代替标记集。<br><img src="/2021/12/08/deconmixeddata/Debledner.jpg">  </p>
<p><strong>Code availability:</strong>   </p>
<ul>
<li>MATLAB  </li>
<li><a href="https://github.com/kondim1983/Deblender/">https://github.com/kondim1983/Deblender/</a>  </li>
</ul>
<h4 id="CDSeq"><a href="#CDSeq" class="headerlink" title="CDSeq"></a><a href="https://doi.org/10.1371/journal.pcbi.1007510">CDSeq</a></h4><p>CDSeq 仅使用来自大量组织样本的 RNA-Seq 数据来同时估计细胞类型比例和细胞类型特异性表达谱。<br><img src="/2021/12/08/deconmixeddata/CDSeq1.jpg"><br><img src="/2021/12/08/deconmixeddata/CDSeq2.jpg">  </p>
<p><strong>Code availability:</strong>   </p>
<ul>
<li>MATLAB and Octave  </li>
<li><a href="https://github.com/kkang7/CDSeq">https://github.com/kkang7/CDSeq</a>  </li>
</ul>
<h4 id="Deconf"><a href="#Deconf" class="headerlink" title="Deconf"></a><a href="https://doi.org/10.1186/1471-2105-11-27">Deconf</a></h4><p>Deconf 证明了从单个样本的基因表达数据中预测构成细胞类型的比例的可行性，这是基于去粗取精的分类方法的前提条件。  </p>
<p><strong>Code availability:</strong>   </p>
<ul>
<li>R  </li>
<li><a href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-11-27/MediaObjects/12859_2009_3484_MOESM1_ESM.ZIP">example data and script</a>  </li>
</ul>
<h3 id="不完全解卷积"><a href="#不完全解卷积" class="headerlink" title="不完全解卷积"></a>不完全解卷积</h3><h4 id="Rodeo"><a href="#Rodeo" class="headerlink" title="Rodeo"></a><a href="https://doi.org/10.1093/nargab/lqaa110">Rodeo</a></h4><p>Rodeo 是一种基于稳健线性回归的方法，可以实现简单而稳健的表达式反卷积。  </p>
<p><strong>Code availability:</strong>   </p>
<ul>
<li>R  </li>
<li><a href="https://github.com/elolab/Rodeo">https://github.com/elolab/Rodeo</a></li>
</ul>
<h4 id="cs-lsfit-amp-cs-qprog"><a href="#cs-lsfit-amp-cs-qprog" class="headerlink" title="cs-lsfit &amp; cs-qprog"></a><a href="https://doi.org/10.1371/journal.pone.0006098">cs-lsfit &amp; cs-qprog</a></h4><p>cs-lsfit 和 cs-qprog 属于 CellMix 中的两个解卷积算法，使用CellMix时可选择使用哪一个来进行解卷积步骤。</p>
<p><strong>Code availability:</strong>   </p>
<ul>
<li>R  </li>
<li><a href="https://github.com/r-forge/cellmix/tree/master/pkg/CellMix">https://github.com/r-forge/cellmix/tree/master/pkg/CellMix</a></li>
</ul>
<h4 id="LRCDE"><a href="#LRCDE" class="headerlink" title="LRCDE"></a><a href="https://doi.org/10.1186/s12859-016-1226-z">LRCDE</a></h4><p>LRCDE 在逐个基因的基础上执行基于线性回归的细胞类型特异性差异表达(反卷积)检测。考虑到细胞类型特异性基因表达估计的变异性，它计算差异检测的每个基因 t 统计量、p 值、基于 t 统计量的灵敏度、组特异性均方误差和几个基因特异性诊断指标。  </p>
<p><strong>Code availability:</strong>   </p>
<ul>
<li>R  </li>
<li><a href="https://github.com/ERGlass/lrcde.dev">https://github.com/ERGlass/lrcde.dev</a></li>
</ul>
<h4 id="csSAM"><a href="#csSAM" class="headerlink" title="csSAM"></a><a href="https://doi.org/10.1038/nmeth.1439">csSAM</a></h4><p>csSAM 根据测量的细胞比例计算细胞特异性差异表达。<br><img src="/2021/12/08/deconmixeddata/csSAM.jpg"></p>
<p><strong>Code availability:</strong>   </p>
<ul>
<li>R  </li>
<li><a href="https://github.com/shenorrLab/csSAM">https://github.com/shenorrLab/csSAM</a>  </li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Maria K Jaakkola, Laura L Elo, Computational deconvolution to estimate cell type-specific gene expression from bulk data, NAR Genomics and Bioinformatics, Volume 3, Issue 1, March 2021, lqaa110, <a href="https://doi.org/10.1093/nargab/lqaa110">https://doi.org/10.1093/nargab/lqaa110</a><br>[2] 具体算法参考文献见算法介绍部分</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>DeconvoluteMixedBioData</category>
      </categories>
      <tags>
        <tag>DeconvoluteMixedBioData</tag>
        <tag>Bioinformatics</tag>
      </tags>
  </entry>
  <entry>
    <title>Methods to Analyze Multi-Omicis Data</title>
    <url>/2021/12/01/multiomics/</url>
    <content><![CDATA[<center>文献阅读：多组学数据的整合、解读方法及公开可用的多组学数据库</center>
<span id="more"></span>

<h2 id="Multi-Omics"><a href="#Multi-Omics" class="headerlink" title="Multi-Omics"></a>Multi-Omics</h2><p><strong>Multi-Omics</strong>指同时获得两个或两个以上组学数据，如基因组、转录组、蛋白质组等，并将它们结合在一起分析、挖掘，以获得更全面、更系统的生物学解释、分子作用机制等。  </p>
<h2 id="多组学研究的意义"><a href="#多组学研究的意义" class="headerlink" title="多组学研究的意义"></a>多组学研究的意义</h2><p>整合多组学数据，提供不同层次的生物分子信息，有望系统地、整体地理解复杂的生物学。<br>多组学研究以顺序或同时的方式结合各组学数据，以了解分子之间的相互作用。<br>有助于评估从一个组学水平到另一个组学水平的信息流，从而有助于弥合从基因型到表型的差距。<br>多组学数据能够为研究提供整体视角，有助于提高疾病表型的预后和预测准确性，进而帮助更好地治疗和预防。  </p>
<h2 id="多组学研究的困难"><a href="#多组学研究的困难" class="headerlink" title="多组学研究的困难"></a>多组学研究的困难</h2><p>多组学的研究通常与非组学数据相关联，如临床数据等，这导致多组学研究面临许多困难。  </p>
<h3 id="非组学数据复杂且主观定义"><a href="#非组学数据复杂且主观定义" class="headerlink" title="非组学数据复杂且主观定义"></a>非组学数据复杂且主观定义</h3><p>非组学数据通常十分复杂且主观性较强，需要标准化后将其加入预测或分类模型中。流行病学数据受制于调查模式、调查问题标准化以及背景，这可能会影响数据质量和可比性，并最终影响这些变量在结果预测中的贡献。不同研究者或组织由于收集程序不一致，也可能产生差异。临床数据受到其定义复杂性的影响，需要有统一的标准。目前有一些标准化的规则可供使用，如Clinical Data Interchange Standards Consortium (CDISC)，Study Data Tabulation Model (SDTM)，Analysis Data Model (ADaM)。这些非组学数据是基于评估者的技能和先前知识的复杂阐述过程产生的主观评估，这可能会导致报告偏差。  </p>
<h3 id="非组学数据具有异质性"><a href="#非组学数据具有异质性" class="headerlink" title="非组学数据具有异质性"></a>非组学数据具有异质性</h3><p>非组学数据缺乏统一性，如不同尺度测量的定性或定量变量等，在分析之前需要对它们进行数据转换或归一化步骤。  </p>
<h3 id="非组学数据规模大"><a href="#非组学数据规模大" class="headerlink" title="非组学数据规模大"></a>非组学数据规模大</h3><p>目前，许多多组学数据与非组学数据相结合的研究方法基于小尺度、低纬度的数据，而现在的非组学数据已经成为“大数据”——大规模，高维度。可穿戴监测装置和EHR (e-health records)的出现使非组学数据更易获取并向更高维度发展，且在处理客观和主观特征以及结构化和非结构化数据方面也更具有挑战性。<br>非组学数据的高维度也意味着存在</p>
<ul>
<li>变量之间的相关结构  </li>
<li>大规模纵向数据  </li>
<li>数据稀疏性（即药物、实验室或诊断测试）  </li>
<li>与组学数据相比，数据缺失与参与个体无关  </li>
</ul>
<p>这些因素都需要在后续分析建模时，将其考虑在内。  </p>
<h3 id="将组学和非组学数据联系"><a href="#将组学和非组学数据联系" class="headerlink" title="将组学和非组学数据联系"></a>将组学和非组学数据联系</h3><p>在病例对照设计中，组学数据和非组学数据的整合可能会受到确认偏差的影响。<br>组学和非组学数据之间的相互作用也会对研究产生影响。在建模的过程中，重要的是要将这种相互作用考虑在内。这些相互作用也可能非常复杂，如基因表达变化可能意味着表型异常，这导致分子数据和临床数据之间的关系更加复杂。  </p>
<h3 id="其它困难"><a href="#其它困难" class="headerlink" title="其它困难"></a>其它困难</h3><p>每个变量或块对结果的贡献是否应该相等。<br>当与高通量数据集结合时，如何防止临床变量被惩罚(penalized)。<br>亚型的出现会给模型增加复杂性，在建模时是否要将亚型考虑在内。</p>
<h2 id="多组学数据库"><a href="#多组学数据库" class="headerlink" title="多组学数据库"></a>多组学数据库</h2><p>多组学数据覆盖基因组、蛋白组、转录组、代谢组和表观遗传组的数据，含有这些组学数据两种或两种以上的数据库可成为多组学数据库。  </p>
<h3 id="TCGA"><a href="#TCGA" class="headerlink" title="TCGA"></a>TCGA</h3><p>The Cancer Genome Altas (<a href="https://cancergenome.nih.gov/">TCGA</a>) 是最大的多组学数据库之一，涵盖超过 33 种不同类型癌症的20000个个体肿瘤样本。TCGA旨在产生、整合、分析和解释肿瘤样本产生的DNA、RNA、蛋白质及表观遗传数据的特征以及临床和组织学数据。</p>
<h3 id="CPTAC"><a href="#CPTAC" class="headerlink" title="CPTAC"></a>CPTAC</h3><p>Clinical Proteomic Tumor Analysis Consortium (<a href="https://cptac-data-portal.georgetown.edu/cptacPublic/">CPTAC</a>) 是通过对TCGA库中的生物样本通过质谱技术进行分析，获取的蛋白质组数据。如果实验中同时测得基因组数据，也可在该库获得。  </p>
<h3 id="ICGC"><a href="#ICGC" class="headerlink" title="ICGC"></a>ICGC</h3><p>International Cancer Genomics Consortium (<a href="https://icgc.org/">ICGC</a>) 从20383名捐献者的21个原发癌位点的76个癌症项目中协调大规模生成基因组研究。  </p>
<h3 id="CCLE"><a href="#CCLE" class="headerlink" title="CCLE"></a>CCLE</h3><p>Cancer Cell Line Encyclopedia (<a href="https://portals.broadinstitute.org/ccle">CCLE</a>) 包含947种人类细胞系和36种肿瘤的基因表达、拷贝数和测序数据。还包含479种癌细胞系中24种抗癌药物的药理学特征。  </p>
<h3 id="METABRIC"><a href="#METABRIC" class="headerlink" title="METABRIC"></a>METABRIC</h3><p>Molecular Taxonomy of Breast Cancer International Consortium (<a href="http://molonc.bccrc.ca/apariciolab/research/metabric/">METABRIC</a>) 包含来自乳腺肿瘤的临床特征、表达、单核苷酸多态性和拷贝数变异数据。  </p>
<h3 id="TARGET"><a href="#TARGET" class="headerlink" title="TARGET"></a>TARGET</h3><p><a href="https://ocg.cancer.gov/programs/target">TARGET</a> 包含 24 种癌症分子类型的临床信息、基因表达、miRNA 表达、拷贝数和测序数据。  </p>
<h3 id="OmicsDI"><a href="#OmicsDI" class="headerlink" title="OmicsDI"></a>OmicsDI</h3><p>Omics Discovery Index (<a href="https://www.omicsdi.org/">OmicsDI</a>) 包含来自公共数据结构中的 11 个存储库的数据集。是一个开源平台，用于访问、发现和整合基因组学、转录组学、蛋白质组学和代谢组学数据集。包含来自人类、模式生物和非模式生物的数据集。  </p>
<h2 id="多组学数据分析方法"><a href="#多组学数据分析方法" class="headerlink" title="多组学数据分析方法"></a>多组学数据分析方法</h2><p>根据算法思想，可将目前已有的多组学数据分析方法分为几个大类：<br><img src="/2021/12/01/multiomics/methods.png">  </p>
<h3 id="Network-Based"><a href="#Network-Based" class="headerlink" title="Network Based"></a>Network Based</h3><p><strong>SNF</strong> (Similarity network fusion)是一种基于网络的方法，使用网络融合方法整合多组学数据集。它为每种数据类型创建一个单独的网络，然后使用非线性网络融合方法将它们融合成一个单一的相似性网络。 融合步骤基于消息传递理论，使网络在每次迭代中更像其他网络。<br><strong>NetICS</strong> (Network-based integration of multi-omics data)为基于网络的多组学数据集成提供了一个框架，用于癌症基因优先排序。可预测遗传畸变、表观遗传变化和miRNA对相互作用网络中下游基因和蛋白质(表达)的影响。在有向功能交互网络上使用每个样本的网络扩散模型，并通过聚合个体排名得出种群水平的基因排名，并为所有样本提供全局排名。  </p>
<h3 id="Bayesian-approach"><a href="#Bayesian-approach" class="headerlink" title="Bayesian approach"></a>Bayesian approach</h3><p><strong>iCluster</strong>根据多种数据类型同时推断，为样本生成一个单一的聚类分配。这种无监督方法使用联合潜在变量模型进行集成聚类，并在单个框架中结合不同数据类型之间的关联以及数据类型内的方差-协方差结构，同时降低数据集的维度。通过期望最大化算法获得似然推理。<br><strong>iClusterPlus</strong>是iCluster的增强版，使用广义线性回归来确定综合基因组、表观基因组和转录组分析的分类和数字(连续和计数)变量的联合模型。该方法使用一组潜在变量”k”来代表驱动因素，这些因素预测关键的基因组变量，从而捕捉生物变异。此外，使用Lasso回归方法，iClusterPlus确定了有助于亚型之间生物变化的特征子集。<br><strong>LRAcluster</strong>使用概率模型与低秩近似法来寻找主要的低维子空间，以对全基因组数据进行分类。在这种方法中，每个组学数据都以大小匹配的参数矩阵为条件，并且这个低秩参数矩阵可以在低维空间中表示。 用户定义的维度参数(基于数据的解释方差)和聚类数(基于轮廓值)有助于更快地降维和更好地聚类疾病亚型。<br><strong>PSDF</strong> (Patient-specific data fusion)该方法使用贝叶斯非参数模型(Dirichlet 过程混合模型)来整合CNV和基因表达数据，以将样本分层为子组。每个样本根据它们在2个数据集之间的一致性被分配一个二元状态。只有表现出一致性的样本融合在一起，而其他样本保持未融合，因此考虑了患者特定的融合模型。<br><strong>BCC</strong> (Bayesian consensus clustering)提出了一种数据驱动的共识聚类方法，该方法对源特定特征以及使用有限狄利克雷混合模型扩展以解释多个数据源的整体聚类进行建模。<br><strong>Joint Bayesian factor</strong>使用非参数贝叶斯因子分析来整合组学数据集。 这种方法使用 beta-Bernoulli 过程将特征空间分解为共享的和特定于数据的组件。<br><strong>MDI</strong> (Multiple dataset integration)使用 Dirichlet 混合模型对每个数据源进行聚类，同时对聚类之间的成对依赖性进行建模。MDI在分配给组件(如基因组特征)的变量级别链接模型。组件变量级链接允许捕获多组学数据之间的依赖关系。<br><strong>MOFA</strong> (Multi-omics factor analysis)是一种无监督方法，用于在相同或部分重叠的样本上整合多组学数据类型。<br><strong>PARADIGM</strong>的应用可以扩展到对所研究疾病的发现。  </p>
<h3 id="Fusion-based-approaches"><a href="#Fusion-based-approaches" class="headerlink" title="Fusion-based approaches"></a>Fusion-based approaches</h3><p><strong>PFA</strong> (Pattern fusion analysis)允许在低维特征空间中跨异质基因组谱识别集成样本模式。首先使用主成分分析获得局部样本模式。 其后将这些局部样本模式与公共特征空间对齐，并跨大多数数据类型合成全局样本模式。在此过程中，将定量测量每种数据类型(或单个样本)对全局样本频谱的贡献，并迭代降低偏差或系统噪声的影响以更好地拟合数据。  </p>
<h3 id="Similarity-based-approaches"><a href="#Similarity-based-approaches" class="headerlink" title="Similarity-based approaches"></a>Similarity-based approaches</h3><p><strong>PINSPlus</strong> (Perturbation clustering for data integration and disease subtyping)是一种无监督的聚类方法，有助于从多组学数据中识别亚型。为了识别亚型，该算法确定患者在单个集群中分组的频率(1)当数据受到干扰时，(2)使用不同类型的组学数据时，(3)使用不同的聚类技术时。 所有场景中的强关联患者都聚集在一起形成一个亚型。<br><strong>NEMO</strong>(Neighborhood-based multi-omics clustering) 是一种基于相似性的简单多组学聚类方法，它进一步建立在先前建立的聚类方法（如 SNF 和 rMKL-LPP）的基础上。该方法最初为每个输入组学数据集构建基于患者间相似性矩阵的欧几里德距离。然后将每个组学的相似性矩阵整合到一个矩阵中，然后使用光谱聚类方法对其进行聚类。  </p>
<h3 id="Correlation-based-approaches"><a href="#Correlation-based-approaches" class="headerlink" title="Correlation based approaches"></a>Correlation based approaches</h3><p><strong>CNAmet</strong>用于对拷贝数改变、DNA 甲基化和基因表达数据进行综合分析。  </p>
<h3 id="Other-multivariate-approaches"><a href="#Other-multivariate-approaches" class="headerlink" title="Other multivariate approaches"></a>Other multivariate approaches</h3><p><strong>mixOmics</strong>提供了一组有监督和无监督的多元方法来执行多组学数据集的整合，重点是变量选择。<br><strong>moCluster</strong>使用多表多元分析方法来识别跨多组学数据集的模式。<br><strong>MCIA</strong> (Multiple co-inertia analysis)是一种探索性数据分析方法，它捕捉多个高维数据集（如基因表达、miRNA表达、蛋白质表达）之间的相互关系。<br><strong>JIVE</strong> (Joint and individual variation explained)通过分离数据集的联合效应和个体效应来整合多组学数据。<br><strong>MFA</strong> (Multiple factor analysis)是一种通过将其投影到低维变量空间来帮助整合组学数据集的方法。<br><strong>rMKL-LPP</strong> 使用多核学习来集成异构多数据并执行子类型识别。<br><strong>iNMF</strong> (Integrative nonnegative matrix factorization)扩展了NMF框架以在集成多个数据时考虑异构效应。<br><strong>FSMKL</strong> (Feature selection multiple kernel learning)是一种监督分类方法，使用多个内核来捕获数据集之间的相似性，以识别疾病进展的特征。<br><strong>sMBPLS</strong> (Sparse multi-block partial least squares)允许多块输入包含多个调控组学数据集，例如 CNV、DNA 甲基化和调控基因表达的 miRNA 表达。<br><strong>T-SVD</strong> (Thresholding singular value decomposition)有助于识别 2 个组学数据集之间的调控机制，尤其是当调控特征大于测量样本时。<br><strong>Joint NMF</strong> 该分解框架从多个数据集(相同样本)中识别相关模块，以推导出 md 模块，以揭示潜在的多层监管因素。  </p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Subramanian I, Verma S, Kumar S, Jere A, Anamika K. Multi-omics Data Integration, Interpretation, and Its Application. Bioinformatics and Biology Insights. January 2020. <a href="doi:10.1177/1177932219899051">doi:10.1177/1177932219899051</a><br>[2] López de Maturana E, Alonso L, Alarcón P, Martín-Antoniano IA, Pineda S, Piorno L, Calle ML, Malats N. Challenges in the Integration of Omics and Non-Omics Data. Genes (Basel). 2019 Mar 20;10(3):238. <a href="doi:10.3390/genes10030238">doi:10.3390/genes10030238</a></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MultiOmics</category>
      </categories>
      <tags>
        <tag>Bioinformatics</tag>
        <tag>MultiOmics</tag>
      </tags>
  </entry>
  <entry>
    <title>长毛象使用指南</title>
    <url>/2021/09/21/mstdn/</url>
    <content><![CDATA[<center>不少朋友被我安利到长毛象(mastodon)玩耍，本着对他们负责的态度，写下这篇长毛象使用指南。</center>
<span id="more"></span>

<h2 id="什么是mastodon"><a href="#什么是mastodon" class="headerlink" title="什么是mastodon"></a>什么是mastodon</h2><p>Mastodon(长毛象)是一个开源、去中心化的社交平台。简单来说，这里没有屏蔽词，没有限流，没有铺天盖地的营销号，没有Doctor看了都想重启宇宙的混乱时间线，只是一个纯粹的社交平台。长毛象将内容、社交网络交还给用户，更加尊重用户而不是平台“霸权”。<br><strong>如果将联邦宇宙(Fediverse)看做一个宇宙，那么每一个长毛象站点(Mastodon Society)就像一颗颗星球。</strong> 也就是说，你可以选择任何一颗星球定居，哪怕只是居住着一个人，只要它与宇宙相通，那么你就可以联系到宇宙中任何一个人而不会孤单。(摘自pullopen对长毛象的介绍：<a href="https://pullopenbluebox.wordpress.com/2020/06/30/mastodon-introduction/">长毛象（Mastodon）：更尊重用户的社交平台</a> )</p>
<h2 id="如何在mastodon拥有一个账号"><a href="#如何在mastodon拥有一个账号" class="headerlink" title="如何在mastodon拥有一个账号"></a>如何在mastodon拥有一个账号</h2><h3 id="选择站点"><a href="#选择站点" class="headerlink" title="选择站点"></a>选择站点</h3><p>长毛象有各种各样的站点(或称实例)，如二次元相关站、LGBTQ站、艺术类站，或者按照语言划分的小语种站点等等。可以在官网列出的<a href="https://joinmastodon.org/communities">站点列表</a>里找到一个喜欢又适合的站点。<br>一开始使用建议在一些大型的国际站点注册，限制较少，每天都有很多世界各地的人在时间线上灌水，如</p>
<ul>
<li><a href="https://mastodon.social/">https://mastodon.social</a></li>
<li><a href="https://mastodon.online/">https://mastodon.online</a></li>
<li><a href="https://mstdn.social/">https://mstdn.social</a>  </li>
</ul>
<p>使用一段时间，对各项操作都熟悉之后，可进一步选择更适合自己的小站点注册并迁移账号，或者继续呆在国际站点也无妨。<br>也可以在中文站点，或者中文用户较多的站点注册。这样在查看local timeline(本地轴)时都是中文，方便遇到志同道合的朋友。但无论在哪个站点注册，都建议阅读过<strong>服务器规则</strong>和<strong>服务条款</strong>后再进行，这两项通常都放在注册页面。<br>熟悉长毛象后，发现没有一个站点完全符合自己的想法，也可以自建站加入长毛象宇宙。搭建长毛象站点有很多简单易上手的教程可供参考，即使是计算机小白也能拥有属于自己的站点。可参考的教程：</p>
<ul>
<li><a href="https://docs.joinmastodon.org/zh-cn/admin/prerequisites/">官方建站文档</a></li>
<li><a href="https://www.notion.so/Mastodon-042a05ee29a048df8b2c1afd49e4c49b">长毛象（Mastodon）社区搭建详解</a></li>
<li><a href="https://pullopen.github.io/%E5%9F%BA%E7%A1%80%E6%90%AD%E5%BB%BA/2020/07/19/How-to-build-a-mastodon-instance.html">技术小白如何搭建Mastodon实例</a></li>
<li><a href="https://morikka.me/blog/mastodon-personal-instance/">长毛象个人向建站</a></li>
</ul>
<h3 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h3><p>只要在一个站点注册，就可以连上整个长毛象宇宙，看到所有在用户和他们公开可见的嘟文，所以只需选择一个合适的站点注册账号即可。但由于站点服务器大多在中国境外，有被墙掉的风险，很多人会选择在多个站点注册账号，避免一个站点被GFW盯上ban掉就难以连上长毛象宇宙。<br>邮箱是各站点注册的必须品，注册成功后也可以更改。建议使用gmail、protonmail等邮箱服务，避免使用qq邮箱一类能直接指向使用者的邮箱。一些站点还需要填写入站申请或入站理由等以便站长和管理员审核注册人，通过审核之后便可成功注册，在长毛象宇宙自由玩耍。</p>
<h2 id="如何使用mastodon"><a href="#如何使用mastodon" class="headerlink" title="如何使用mastodon"></a>如何使用mastodon</h2><h3 id="Timeline-时间轴"><a href="#Timeline-时间轴" class="headerlink" title="Timeline(时间轴)"></a>Timeline(时间轴)</h3><p>Timeline简称为TL，完全按照时间来排列嘟文，不必担心出现时间线混乱、只给你看热度高的嘟文或塞给你不想看的广告、推广。<br>一般情况下，时间线有三种：</p>
<ul>
<li><strong>Home</strong> timeline，简称HTL，即首页。这是账号持有人自行关注而产生的时间线，能看到public、unlist、followers-only的嘟文(包括回复)以及提到你的direct message。</li>
<li><strong>Local</strong> timeline，简称LTL，即本站(地)轴。这是账号所在站点的时间线，只有该站点的公开嘟文会出现在这里。</li>
<li><strong>Federate</strong> timeline，简称FTL，即跨站轴。这是无论站点、所有账号嘟出的public内容共同组成的时间轴，能够看到世界各地的人都在这里发出自己的嘟嘟。</li>
</ul>
<p>通过设置<code>preferences (首选项) -&gt; other (其它) -&gt; PUBLIC TIMELINES-Filter languages (公共时间轴-语言过滤)</code>，可过滤时间线上的语言，只留下自己想看的语言。但这个过滤并不完全，公共轴或本站轴仍会出现一些应该被过滤掉的语言。 </p>
<h3 id="基本功能"><a href="#基本功能" class="headerlink" title="基本功能"></a>基本功能</h3><ul>
<li><p>发嘟  </p>
<ul>
<li>可见范围<br>发嘟可选择四种可见范围：public (公开)，unlist (公开，但不出现在公共时间轴)，followers-only (仅关注者可见)，direct message (私信，也可用作发仅自己可见的嘟文)。在设置中可以选择默认发嘟可见范围。</li>
<li>cw折叠功能<br>一些不想被直接看到或者含有可能令人不适内容的嘟文推荐使用cw。点击发嘟窗口下方的cw就会出现一个新的小窗口，在这个新的小窗口填上内容提示信息，在发嘟主要窗口填写主要内容。<del>这个功能也很好地被用来讲冷笑话</del>  </li>
<li>标记敏感内容<br>如果发的嘟文/图片含有not safe for work(NSFW，包括色情、暴力、血腥等)的内容，需要在发嘟时将图片标记为敏感信息，且善用cw折叠功能。</li>
</ul>
</li>
<li><p>回复<br>左下角箭头是回复功能，回复也可以设置不同的可见范围。在此处如果设置followers-only，被回复者即使没有关注你，也可以看到。回复的嘟嘟仅会出现在同时关注对话双方的账号首页时间线(Home Timeline)。这样尽最大可能避免参与对话者以外的人的打扰，使对话双方处于平等地位，不会出现因一方粉丝过多看到回复一拥而上的现象。各个时间轴设置(一般在主区域右上角)中可设置该时间轴不显示回复类嘟文。</p>
</li>
<li><p>转发<br>长毛象的转发是仅转发，不能带文字。这样很好的避免了类似微博上转发挂人形成骂战的现象。在账号设置中选择<code>在时间轴中合并转嘟</code>，以避免一篇嘟文被太多人转发刷屏时间轴的情况。各个时间轴设置(一般在主区域右上角)中可设置该时间轴不显示转发类嘟文，公共轴一般默认不显示转发。</p>
</li>
<li><p>喜欢<br>这里的⭐是favourite的意思，类似点赞功能。点赞代表赞同、安慰还是这里有个言论我mark一下就看使用者自己的想法，但通常来说都是<strong>赞</strong>！  </p>
</li>
<li><p>书签<br>bookmark是书签，或者称为收藏功能，这个功能与大多数平台相似，不再赘述。</p>
</li>
</ul>
<h3 id="头像、昵称、profile、标签"><a href="#头像、昵称、profile、标签" class="headerlink" title="头像、昵称、profile、标签"></a>头像、昵称、profile、标签</h3><p>一些站点固定期限内没有头像、昵称和嘟文的“三无账号”会被清除收回，注意阅读站点规则避免注册之后账号被回收。既然已经决定抛弃微博等在用户时间线上搞动作的平台，就不要只是注册个账号放着，用起来！</p>
<h3 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h3><ul>
<li><p>锁嘟<br>锁定账号(选项在个人资料页面)，需要手动审核所有关注请求。即每个想要关注你账号的人需要先发送关注请求，你通过之后方可关注你的账号以及看到你的followers-only的嘟文。与instgram的锁账号不同，即使挂上小锁其他人仍能看到公开可见的嘟文。如果有较多敏感嘟文不想随意被人看到，可定期删除或选择followers-only、direct message这两种可见范围。</p>
</li>
<li><p>语言<br>通过<code>Preferences (首选项) -&gt; Appearance (外观) -&gt; Interface language (界面语言)</code>设置平台语言。由于各语种都是志愿者翻译，可能会出现错误或词不达意，但基本不影响使用。</p>
</li>
<li><p>过滤器<br>这里的过滤器是真的过滤掉包含关键字的嘟文，但可能会在原本应该是一条嘟文的地方出现<code>filtered</code>的提醒。过滤器可以设置失效时间、作用场景等。</p>
</li>
<li><p>邮件通知<br><code>Preferences (首选项) -&gt; Notifications (通知)</code>里的邮件提醒建议关掉，避免发送过多邮件给站长的邮件服务造成不必要的负担。</p>
</li>
<li><p>其它<br>界面语言设置为惯用语言后，其它设置可自行探索。</p>
</li>
</ul>
<h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><p>Mastodon故意弱化了搜索功能，避免形成“广场”，从而导致有人随便搜索一个关键词便前来抬杠或骂人的行为。但这也在一定程度上造成使用者的不便，比如明明有印象一条嘟嘟，但根本找不到，所以需要使用者自己多注意收藏有用的信息。有些站点开了全文搜索，会让搜索结果好一些，如自己的嘟文或转发、点赞过的嘟文能够搜索，但无法实现真正的“搜索”。 </p>
<h3 id="block-mute"><a href="#block-mute" class="headerlink" title="block / mute"></a>block / mute</h3><p>block即拉黑/屏蔽。拉黑后，该账号无法与你互动、关注，嘟文不会出现在你的时间线。<br>mute即隐藏。隐藏后，该账号的嘟文不会出现在你的时间线，但仍可与你互动、关注，而你不会收到任何提醒。</p>
<h3 id="迁移账号"><a href="#迁移账号" class="headerlink" title="迁移账号"></a>迁移账号</h3><p>长毛象的一大优点就是站点多，且类型丰富。如果看上了别的站点，可以在新站点注册账号后将账号迁移过去。迁移账号可以自动将followers/following转移到新账号，但无法迁移旧帐号的嘟文。</p>
<h3 id="账号备份"><a href="#账号备份" class="headerlink" title="账号备份"></a>账号备份</h3><p>长毛象自带的备份功能可以备份follower列表、following列表、mute列表、block列表等。如果想要备份嘟文，可以使用象友提供的<a href="https://github.com/slashyn/mastodon-archive-viewer-modified">备份插件</a>。<br>由于各个站点的维护仅依赖站长和可能有的站点管理员，所以可能会有不稳定、服务器出问题等状况出现，有时整个站点也会关闭不再运行，及时备份账号内容是个好习惯。</p>
<h3 id="app"><a href="#app" class="headerlink" title="app"></a>app</h3><p>长毛象作为一个去中心化的平台，最佳访问方式是直接浏览器访问，如Chrome、Firefox、safari等。这些浏览器可以在手机主屏幕创建快捷方式，在手机桌面单独形成一个图标和有一个app没有太大差别。<br>如果仍需要一个app，可选择的有：</p>
<ul>
<li><p><strong>Android</strong>: Tusky, Subway Tooter, Fedilab(付费)</p>
</li>
<li><p><strong>iOS</strong>: Metatext, Mercury, iMast, Amaroq, Mast(付费), Toot!(付费)  </p>
</li>
<li><p><strong>tooot</strong>：对于中文用户，推荐使用tooot。这是一个专注于中文社区的简洁、开源长毛象手机客户端，跨平台支持iOS和Android。 </p>
</li>
<li><p><strong>其它</strong>：其它平台应用推荐可查看<a href="https://joinmastodon.org/apps">官网应用推荐</a>。  </p>
</li>
</ul>
<h3 id="tag"><a href="#tag" class="headerlink" title="tag"></a>tag</h3><p>作为一个公共社交网络，这里也可以带话题(tag)发嘟。格式和Instagram一样，只需要一个<code>#</code>，如<code>#tag</code>。<br>长毛象已经有很多有趣或有用的tag，如<code>#长毛象中文使用指南</code>、<code>#长毛象安利交换大会</code>、<code>#资源分享</code>、<code>#菜谱</code>，还有季节性的赏花、赏月tag。也可以创建自己的专属tag，把某类嘟文存在这个tag下，方便自己查看。</p>
<h3 id="一些好玩的账号"><a href="#一些好玩的账号" class="headerlink" title="一些好玩的账号"></a>一些好玩的账号</h3><ul>
<li><p>骰寶機<br>吃喝玩乐都可以找它！想不到晚饭吃什么，发嘟@骰宝问吃什么，不出一分钟就会回复一种食物。问它喝什么同理。还有好玩又有趣的答案之书和对不对判断。具体玩法可查看骰宝账号主页了解。</p>
</li>
<li><p>妙仙包<br>想知道心中之事的结果？找大师求签、塔罗牌都能给你一个奇妙的答案。选择困难症？找包包真普选，轻松治愈选择困难。心中有愿还可对着大师许愿，有机会被大师选中实现。具体玩法查看妙仙包账号主页了解。</p>
</li>
<li><p>sci咖啡屋<br>这里可以点单饮品、套餐，但一定要吃完不可浪费。累了还可以在这里撸猫，猫猫送上缓解疲惫。具体玩法查看sci咖啡屋账号主页了解。</p>
</li>
<li><p>Mature[マツレ]<br>Mature是长毛象上最早的科学期刊之一，也是长毛象最权威及最有名望的学术期刊之一。每周最重要、最前沿的研究结果是在「Mature」中以论文导读的形式发表的。欢迎订阅，支持投稿。投稿方法详见Mature账号主页。</p>
</li>
</ul>
<p>以上有趣账号可通过搜索名称获得，在此不提供具体账号以免给站点造成麻烦。</p>
<h2 id="More-than-Mastodon"><a href="#More-than-Mastodon" class="headerlink" title="More than Mastodon"></a>More than Mastodon</h2><p>其实mastodon只是这个宇宙中的一部分，还有Misskey、pleroma、funkwhale、peertube等和mastodon类似的社交平台共同组成整个联邦宇宙。<br>何必拘泥于处处受限的一隅，这里有更广阔的宇宙等你。<br>Enjoy yourself！</p>
]]></content>
      <categories>
        <category>Mastodon</category>
        <category>Use</category>
      </categories>
      <tags>
        <tag>Mastodon</tag>
        <tag>UserGuide</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo + Markdown写博客</title>
    <url>/2021/09/16/writenewblog/</url>
    <content><![CDATA[<center>创建、发布新文章；用vscode + markdown编辑文章；给文章添加分类和标签。</center>
<span id="more"></span>

<h2 id="新建文章-create-a-post"><a href="#新建文章-create-a-post" class="headerlink" title="新建文章 create a post"></a>新建文章 create a post</h2><p>在博客目录运行命令：</p>
<pre><code>$ hexo new [layout] title
# layout有三种:post, draft, page, 默认是post，可以在博客配置文件中更改default_layout来更改默认设置
# Hexo会根据scaffolds文件夹内相对应的文件来建立md文件
# 当创建不同布局的md文件时，它们会存储在不同路径

$ hexo new &quot;My New Post&quot;
#新建一个名为&quot;My New Post&quot;的md文件
</code></pre>
<p>后续编辑这个文件即可。</p>
<h2 id="vscode-markdown写文章"><a href="#vscode-markdown写文章" class="headerlink" title="vscode + markdown写文章"></a>vscode + markdown写文章</h2><p>可按照以下步骤编辑一遍博客文章：</p>
<ol>
<li>从<a href="https://code.visualstudio.com/">官网</a>下载vscode，并安装。  </li>
<li>安装markdown插件：<ul>
<li>Markdown All in One: 组合包，把最常用的Markdown优化全部装好</li>
<li>Markdown Preview Github Styling: 在本地就能预览Markdown文件最终在Github Pages中显示的效果</li>
</ul>
</li>
<li>学习基本的markdown语法，利用vscode编辑文章。同时，利用”Open Preview to the Side”按键或快捷键可同时预览文章</li>
<li>写完这篇文章</li>
</ol>
<h2 id="categories"><a href="#categories" class="headerlink" title="categories"></a>categories</h2><h3 id="生成categories页并修改type属性"><a href="#生成categories页并修改type属性" class="headerlink" title="生成categories页并修改type属性"></a>生成categories页并修改type属性</h3><p>在博客目录运行命令行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new page categories</span><br></pre></td></tr></table></figure>
<p>运行成功后会提示：</p>
<pre><code>INFO  Created: ~/Documents/blog/source/categories/index.md
</code></pre>
<p>根据所给路径找到index.md文件，在文件的框架内添加一行：</p>
<pre><code>type: &quot;categories&quot;
</code></pre>
<h3 id="给文章添加categories"><a href="#给文章添加categories" class="headerlink" title="给文章添加categories"></a>给文章添加categories</h3><p>在文章头的<code>categories:</code>后以<code>-</code>为标志添加标签，如本文的标签：</p>
<pre><code>categories:
- Blog #注意“-”后一定要加空格
</code></pre>
<h2 id="tag"><a href="#tag" class="headerlink" title="tag"></a>tag</h2><h3 id="生成tag页并修改type属性"><a href="#生成tag页并修改type属性" class="headerlink" title="生成tag页并修改type属性"></a>生成tag页并修改type属性</h3><p>在博客目录运行命令行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new page tags</span><br></pre></td></tr></table></figure>
<p>运行成功后会提示：</p>
<pre><code>INFO  Created: ~/Documents/blog/source/tags/index.md
</code></pre>
<p>根据所给路径找到index.md文件，在文件的框架内添加一行：</p>
<pre><code>type: &quot;tags&quot;
</code></pre>
<h3 id="给文章添加tag"><a href="#给文章添加tag" class="headerlink" title="给文章添加tag"></a>给文章添加tag</h3><p>在文章头的<code>tags:</code>后以<code>-</code>为标志添加标签，如本文的标签：</p>
<pre><code>tags: 
- Blog #注意“-”后一定要加空格
- Hexo
- Markdown
- vscode
</code></pre>
<h2 id="文章的发布"><a href="#文章的发布" class="headerlink" title="文章的发布"></a>文章的发布</h2><p>在博客目录运行命令：</p>
<pre><code>$ hexo generate
$ hexo server  # 本地预查看
$ hexo deploy  # 部署到GitHub Pages

# 此步骤报错可先检查文件头等文章各部分是否缺少空格
</code></pre>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/156915260">Hexo博客写文章及基本操作</a></li>
<li><a href="https://linlif.github.io/2017/05/27/Hexo%E4%BD%BF%E7%94%A8%E6%94%BB%E7%95%A5-%E6%B7%BB%E5%8A%A0%E5%88%86%E7%B1%BB%E5%8F%8A%E6%A0%87%E7%AD%BE/">Hexo使用攻略-添加分类及标签</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/56943330">[Markdown] 使用vscode开始Markdown写作之旅</a></li>
</ol>
]]></content>
      <categories>
        <category>Blog</category>
        <category>Writing</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Blog</tag>
        <tag>Markdown</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title>Batch Effects Matter and Avoid Them in Omics Data</title>
    <url>/2021/10/29/BatchEffect/</url>
    <content><![CDATA[<center>文献阅读：关于批次效应的3W1H——什么是批次效应、什么情况下会出现批次效应、为什么要关注批次效应与如何处理批次效应</center>
<span id="more"></span>

<h2 id="什么是批次效应"><a href="#什么是批次效应" class="headerlink" title="什么是批次效应"></a>什么是批次效应</h2><p><strong>批次效应</strong>是指实验子组在不同的实验条件之下具有与研究中的生物学或其它科学变量无关的性质不同的行为，即实验中测量值之间由于技术因素造成的系统性差异。</p>
<br>

<h2 id="什么情况下会有批次效应"><a href="#什么情况下会有批次效应" class="headerlink" title="什么情况下会有批次效应"></a>什么情况下会有批次效应</h2><p>批次效应在生物学实验中广泛存在，无论是microarray expression profiling还是mass spectrometry产生的数据，都观察到明显的批次效应。具体到研究疾病的差异基因/蛋白或变异数据(如拷贝数变异)的研究中同样观察到明显批次效应。<br>造成批次效应的因素有很多，试剂批次不同、实验时间不同、仪器状态变化、实验员不同都可能造成批次效应。其中一些批次效应能够通过规范化实验操作、更好的实验设计避免；另一些则需要通过对所得数据进行处理才能够消除。<br>在Leek等人对已公开数据批次效应的研究发现，已公开的数据中存在明显批次效应。且在许多实验条件和技术中，技术性因素比生物性因素对实验结果更具影响力。当批次效应发生时，常常与生物性因素混淆，导致下游研究结果不准确。  </p>
<br>

<h2 id="为什么要关注批次效应"><a href="#为什么要关注批次效应" class="headerlink" title="为什么要关注批次效应"></a>为什么要关注批次效应</h2><p>当批次效应发生时，可能会</p>
<ul>
<li>增加变化(variability)而掩盖真正生物学信号，导致得到错误的生物学或临床结论  </li>
<li>与特征信号混在一起，导致下游分类器构建困难  </li>
<li>阻碍生物学上重要亚型的发现或与亚型混淆难以区分  </li>
<li>导致实验资源分配不当，结果缺乏可重复性  </li>
</ul>
<p>因此，消除批次效应对得到准确、可重复性高的结论非常重要。</p>
<br>

<h2 id="如何避免或处理批次效应"><a href="#如何避免或处理批次效应" class="headerlink" title="如何避免或处理批次效应"></a>如何避免或处理批次效应</h2><h3 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h3><p>避免出现批次效应的首要步骤是合理的实验设计。高通量的实验应在实验设计时考虑到批次效应，在实验过程中尽可能避免批次效应的出现。实验分组时也需保证平衡性(balance)，避免非研究目标的生物学因素对实验结果造成影响，进而和批次效应混杂，导致数据难以处理。  </p>
<h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p>优秀的实验设计是降低批次效应的基础，在此基础之上处理批次效应主要有以下两个步骤：</p>
<ol>
<li>识别并量化数据中潜在的批次效应，包括人为因素  </li>
<li>使用已知或找到的人为因素调整数据以适应下游分析</li>
</ol>
<h4 id="识别并量化批次效应"><a href="#识别并量化批次效应" class="headerlink" title="识别并量化批次效应"></a>识别并量化批次效应</h4><p>识别和量化批次效应主要通过主成分分析(Principal Component Analysis, PCA)或其它数据可视化工具如聚类、多维数据标化等。<br>如果数据处理结果中出现：  </p>
<ul>
<li>样本按处理组或时间聚类</li>
<li>大量特征与处理组或时间高度相关</li>
<li>主成分与批次处理组或时间相关联  </li>
</ul>
<p>则表明数据中极大可能存在批次效应，必须在下游数据处理前考虑到批次效应的影响。</p>
<h4 id="处理批次效应"><a href="#处理批次效应" class="headerlink" title="处理批次效应"></a>处理批次效应</h4><p>根据其算法思想可将消除批次效应的方法分为如下几个大类：  </p>
<ul>
<li><strong>简单线性模型(Simple Linear Models)</strong>: Mean-scaling, zero-centering  </li>
<li><strong>经验贝叶斯方法(Empirical Bayes)</strong>: ComBat  </li>
<li><strong>因子分析(Factor-based analysis)</strong>: Surrogate Variable Analysis (SVA), Removed unwanted variation (RUV)  </li>
<li><strong>深度学习(Deep Learning)</strong>: NormAE</li>
</ul>
<p>其中，前两种消除批次效应的方法需要已知造成批次效应的因素，如实验时间等。  </p>
<p>根据先验知识、实验数据规模、特征空间大小、研究目的等因素，可挑选不同的处理批次效应的方法：</p>
<ul>
<li>大数据；特征空间有限；有限的生物异质性；批次效应或分类影响因子已知；目标是简单分析：<strong>Two-way ANOVA</strong>  </li>
<li>小数据；特征空间有限；有限的生物异质性；批次效应或类影响因子已知；目标是去除批次效应：<strong>ComBat</strong>  </li>
<li>中/大型数据集；大特征空间；存在生物异质性；类因子已知，批次效应影响因素不必已知；目标是移除批次效应且确定批次效应影响因素：<strong>SVA</strong>, <strong>RUV</strong>  </li>
<li>中/大型数据集；大特征空间；存在生物异质性；批次效应或分类影响因子都不必已知；目标是移除批次效应且确定批次效应影响因素但不需直到类因子：<strong>unsupervised methods (PCA)</strong>, <strong>RUV</strong></li>
</ul>
<p>算法补充：<br><img src="/2021/10/29/BatchEffect/Methods.png" alt="算法补充1"><br><img src="/2021/10/29/BatchEffect/Methods2.png" alt="算法补充2">  </p>
<h4 id="批次效应处理评估"><a href="#批次效应处理评估" class="headerlink" title="批次效应处理评估"></a>批次效应处理评估</h4><p>消除批次效应之后，通常会检查处理的效果。常用的方法有PCA、层次聚类等，检查数据是否有与批次相关联的偏移、聚类结果是否更符合生物学先验知识等。<br>评估方法小结：<br><img src="/2021/10/29/BatchEffect/Validation.png" alt="批次效应评估方法">  </p>
<br>

<h2 id="批次效应处理流程"><a href="#批次效应处理流程" class="headerlink" title="批次效应处理流程"></a>批次效应处理流程</h2><p>Jelena Čuklina等人针对批次效应的研究中提供了一个消除蛋白质数据批次效应的处理流程和一个包含所有处理步骤的R包——proBatch (<a href="https://www.bioconductor.org/packages/release/bioc/html/proBatch.html">Bioconductor</a>, <a href="https://hub.docker.com/r/digitalproteomes/probatch">Docker container</a>, <a href="https://github.com/symbioticMe/batch_effects_workflow_code">GitHub repository</a>都可获取该R包)  </p>
<h3 id="流程图总览"><a href="#流程图总览" class="headerlink" title="流程图总览"></a>流程图总览</h3><p><img src="/2021/10/29/BatchEffect/workflow.png" alt="批次效应处理流程图">  </p>
<ol>
<li>初步评估原始数据中是否存在批次效应  </li>
<li>归一化使数据集中所有数据在同一尺度  </li>
<li>归一化后数据评估，以确定数据是否需要进一步处理  </li>
<li>批次效应校正以纠正特征偏移  </li>
<li>质量控制测试：是否在保留有意义信号的同时减少了数据偏差  </li>
</ol>
<h3 id="Raw-Data-Matrix"><a href="#Raw-Data-Matrix" class="headerlink" title="Raw Data Matrix"></a>Raw Data Matrix</h3><p>在进行这一流程之前，应当先对数据进行预处理，如肽段识别、肽段定量、FDR筛选、log-transformed或variance stabilizing transformation。<br>虽然在ion fragment、peptides、protein层面都可以识别并处理批次效应，但因为这个过程改变了对蛋白质推断至关重要的特征丰度，最好针对ion fragment或peptides数据处理批次效应。且在处理过程中应包含尽可能多的数据以保证数据分布最接近真实情况。  </p>
<h3 id="Initial-Assessment"><a href="#Initial-Assessment" class="headerlink" title="Initial Assessment"></a>Initial Assessment</h3><p>这一步骤主要目的是确定数据的偏移程度并确定一个归一化方法。通常情况下，样本间intensity会有一定差异，调整这种差异有助于数据的比较，能够更好地识别出需要进一步处理的因素。主要方法有三种：</p>
<ol>
<li>按照质谱测量或技术批次的顺序绘制样品强度平均值或中值，评估每个批次中的质谱漂移或离散偏差  </li>
<li>箱线图，评估样本方差和异常值  </li>
<li>批次间与批次内样本相关性  </li>
</ol>
<p>通过上述步骤来检验</p>
<ul>
<li>数据分布是否具有一致性  </li>
<li>样本间的相关性  </li>
<li>如果有差异，这种差异是否与批次相关联  </li>
</ul>
<h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><p>归一化的目的就是将所有样本的数据处于同一尺度，使得跨样本数据能够互相比较。常用的归一化方法有quantile normalization、median normalization和z-transformation，应根据数据的异质性和数据分布情况选择合适的归一化方法。  </p>
<h4 id="数据的异质性"><a href="#数据的异质性" class="headerlink" title="数据的异质性"></a>数据的异质性</h4><ul>
<li><strong>数据相似程度高：</strong> quantile normalization  </li>
<li><strong>数据具有本质差异：</strong> HMM-assisted normalization  </li>
<li><strong>数据会有包含信息的异常值(outliers)：</strong> 选择能够保留异常值与总体数据关系的归一化方法  </li>
</ul>
<h4 id="样本丰度分布"><a href="#样本丰度分布" class="headerlink" title="样本丰度分布"></a>样本丰度分布</h4><ul>
<li>通常情况下，只需调整数据中位数或平均值  </li>
<li>如果出现方差差异较大，也需要将它们调整到同一尺度</li>
</ul>
<p>归一化步骤应尽可能简单直接，对数据的操作越少，越能够保留数据的真实情况。归一化后可通过diagnostic plots和quality control方法对数据进行评估。</p>
<h3 id="Diagnostics-of-normalized-data"><a href="#Diagnostics-of-normalized-data" class="headerlink" title="Diagnostics of normalized data"></a>Diagnostics of normalized data</h3><p>评估归一化后的数据以确定是否需要进一步的处理，主要方法为：</p>
<ul>
<li><strong>Hierarchical clustering：</strong>  将相似的样本分组为树状结构，观察聚类结果是否和批次相关  </li>
<li><strong>Principal Component Analysis(PCA):</strong> 观察主成分是否与批次相关联，对评估聚类依据是生物还是技术因素及检查重复组相似性十分有效  </li>
</ul>
<p>上述方法要求数据中没有缺失值，而蛋白质组数据通常含有缺失值。填补缺失值时应特别注意尽可能保留数据原有的分布，不能盲目填0或一个较小的随机数。<br>蛋白质组通常使用肽段数据检查是否存在与批次相关的偏移。如在DIA数据中加入iRT肽段用于数据特征校正。由于不同肽段对不同批次效应的response不同，有必要检查大量肽段以确定是否存在批次效应。通过检查肽段数据还能够确认跑样顺序是否对数据造成影响，是否有与顺序相关的变化趋势(trends)。<br>还可以用ion fragments的数据校正蛋白数据，但目前针对肽段的方法更加广泛。  </p>
<h3 id="Batch-effect-correction"><a href="#Batch-effect-correction" class="headerlink" title="Batch effect correction"></a>Batch effect correction</h3><p>归一化能够校准数据的全局，而批次效应校正主要针对特征峰和特征组。根据批次效应的形式，可将消除批次效应的方法分为两大类：</p>
<ul>
<li><strong>Continuous</strong><br>消除连续的批次效应主要通过拟合的方式，如LOESS fit，或使用其它连续算法。<br>在质谱大数据(hundreds of samples)中会出现信号漂移现象，这仍是一个亟待解决的问题。  </li>
<li><strong>Discrete</strong><br>消除离散的批次效应时常用mean and median centering。<br>基于贝叶斯模型的ComBat算法也能够用于处理蛋白质数据，但需要已知所有的批次效应影响因素。</li>
</ul>
<h3 id="Quality-control"><a href="#Quality-control" class="headerlink" title="Quality control"></a>Quality control</h3><p>质控步骤主要用于评估归一化和批次效应校正之后的数据质量，好的数据校正应做到消除偏移(negative control)和提升数据(positive control)两方面。  </p>
<ul>
<li><strong>消除偏移的标准</strong>  <ul>
<li>聚类或PCA后，同组数据聚集依据与批次无关，更多地受生物学因素影响  </li>
<li>肽段(或其他特征，如ion fragments)没有与批次相关的偏移  </li>
</ul>
</li>
<li><strong>提升数据</strong><ul>
<li>通常情况下，数据提升的标准为聚类结果更符合生物学先验知识，后续差异检验步骤能够识别出更多差异。但这种标准并不具有足够的客观性，尤其是后一个标准并不一定表明数据提升，还有可能是false positive  </li>
<li>交叉验证：差异表达蛋白或最佳分类特征蛋白列表高度重合。但这种方法依赖于数据集和特征空间的大小，当数据集较小，后一个蛋白列表本身不稳定，会对评估造成影响。在另一篇综述中强调应避免交叉验证来评估数据质量  </li>
<li>检查重复组间的方差：如果数据的归一化和消除批次效应步骤合理，重复组间的方差应降低  </li>
<li>样本间相关性：技术或生物学重复样本间的相关性应明显高于与其它样本的相关性  </li>
<li>距离矩阵：与上一方法的逻辑相似，但通过计算样本间距离来评估数据  </li>
<li>肽段间的相关性：来自同一蛋白的肽段具有正相关或高相关性，而来自不同蛋白或不相关的肽段间的相关性应接近于0  </li>
</ul>
</li>
</ul>
<br>

<h2 id="消除批次效应的方法-工具"><a href="#消除批次效应的方法-工具" class="headerlink" title="消除批次效应的方法/工具"></a>消除批次效应的方法/工具</h2><h3 id="ComBat"><a href="#ComBat" class="headerlink" title="ComBat"></a>ComBat</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>ComBat基于参数和非参数经验贝叶斯框架，用于调整具有批次效应的数据。该方法对小样本中的异常值具有健壮性，并且与大样本的现有方法相当。<br>以Microarray为研究对象。  </p>
<h4 id="经验贝叶斯框架使用基础"><a href="#经验贝叶斯框架使用基础" class="headerlink" title="经验贝叶斯框架使用基础"></a>经验贝叶斯框架使用基础</h4><ul>
<li>已经广泛用于大规模microarray数据：稳定具有极高或极低比率的基因的表达比，缩小所有其他基因的方差来稳定基因方差避免伪影的影响等  </li>
<li>已有批次效应处理方法(如SVD、DWD和L/S method)需要大批量数据，且不能兼容小批次数据的离群值  </li>
<li>对高位效数据组有较强的健壮性  </li>
<li>利用跨基因和跨样本的“借用信息”，以得到更好的估计或更稳定的结果  </li>
</ul>
<h4 id="基本假设"><a href="#基本假设" class="headerlink" title="基本假设"></a>基本假设</h4><ul>
<li>结合基因间常见的系统批次效应，假设导致批次效应的现象通常以相似的方式影响许多基因  </li>
<li>通过汇集信息(pooling information)来估计代表批次效应的L/S模型参数，在每个批次的基因中缩减(shrink)批次效应参数估计值，使之朝着批次效应估计值的总体平均值(跨基因)发展  </li>
<li>数据已被归一化，所有样本的基因表达值已被估计  </li>
</ul>
<h4 id="关键步骤"><a href="#关键步骤" class="headerlink" title="关键步骤"></a>关键步骤</h4><ol>
<li>Standardize the data  </li>
<li>EB batch effect parameter estimates using parametric empircal priors  </li>
<li>Adjust the data for batch effects  </li>
</ol>
<h3 id="QC-RLSC"><a href="#QC-RLSC" class="headerlink" title="QC-RLSC"></a>QC-RLSC</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>QC-RLSC(quality control-based robust LOESS signal correction)可用于信号校正和整合来自不同实验批次的数据。<br>以Metabolics数据为研究对象。  </p>
<h4 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h4><p>LOESS曲线拟合结合了经典的线性最小二乘法回归的简单性和非线性回归的灵活性。它通过对数据的局部子集进行简单的模型拟合来建立一个函数，逐点地描述数据中的确定性变化部分。不需要指定任何形式的全局函数来拟合数据的模型，而只需要拟合数据的片段。<br>对数据的每个子集进行拟合的局部多项式被限制为一阶或二阶(即局部线性或局部二阶)，并使用加权最小二乘法拟合(标准三立方权重函数)。<br>优化平滑参数(或称跨度)以获得更好的回归曲线。不使用过小的平滑参数以避免曲线受到随机误差的影响。<br>留一法交叉验证(leave-one-out cross validation)以避免过拟合。  </p>
<h4 id="关键步骤-1"><a href="#关键步骤-1" class="headerlink" title="关键步骤"></a>关键步骤</h4><ol>
<li>在实验结束、色谱解卷积后，使用QC-RLSC对数据进行标准化(normalize)</li>
<li>依据注入顺序，对质控数据进行LOESS拟合</li>
<li>对整个分析运行的校正曲线进行内插，并对该特征的总数据集进行标准化</li>
</ol>
<p>通过这些步骤，在一次分析中，峰响应的任何衰减都被最小化。</p>
<h3 id="ICA"><a href="#ICA" class="headerlink" title="ICA"></a>ICA</h3><h4 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h4><p>使用时空独立成分分析(spatio-temporal independent component analysis)对批次效应建模，并移除这些影响。<br>以microarray datasets为研究对象。  </p>
<h4 id="基本原理-1"><a href="#基本原理-1" class="headerlink" title="基本原理"></a>基本原理</h4><p>对整合的数据集进行因子分解(factorization)，移除与子数据集具有某种相关性的组件，以获得最终数据集。这一过程能够从数据中移除批次效应。<br>去除的成分是可以解释的，很容易检查它们是否与某些感兴趣的生物信息相关。<br>ICA被证明能更好地模拟不同的变异(variables)来源。  </p>
<h4 id="关键步骤-2"><a href="#关键步骤-2" class="headerlink" title="关键步骤"></a>关键步骤</h4><p>假设汇总的数据集是一个按样本划分的基因矩阵<em>X</em>，<em>X</em><sub>i,j</sub> 表明gene <em>i</em> 在样本 <em>j</em> 中的表达量。<br><img src="/2021/10/29/BatchEffect/ICAsteps.png" alt="ICA流程">  </p>
<h3 id="WaveICA"><a href="#WaveICA" class="headerlink" title="WaveICA"></a>WaveICA</h3><h4 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h4><p>WaveICA基于带有小波变换的独立成分分析，作为大规模代谢组学数据的阈值处理方法捕获并去除批次效应。<br>研究对象为Metabolics数据。  </p>
<h4 id="基本原理-2"><a href="#基本原理-2" class="headerlink" title="基本原理"></a>基本原理</h4><p>利用样品在注射顺序中的时间趋势，将原始数据分解为具有不同特征的多尺度数据，提取并去除多尺度数据中的批次效应信息，获得干净的数据。<br>在实际问题中DWT有局限性，WaveICA中使用的小波变换为Maximal overlap discrete wavelet transform (MODWT)。  </p>
<h4 id="关键步骤-3"><a href="#关键步骤-3" class="headerlink" title="关键步骤"></a>关键步骤</h4><p><img src="/2021/10/29/BatchEffect/WaveICA.png" alt="WaveICA流程">  </p>
<h3 id="NormAE"><a href="#NormAE" class="headerlink" title="NormAE"></a>NormAE</h3><h4 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h4><p>Normlization Autoencoder(NormAE)基于非线性自编码器和对抗性学习的新型深度学习模型。<br>研究对象为Metabolics数据。  </p>
<h4 id="基本原理-3"><a href="#基本原理-3" class="headerlink" title="基本原理"></a>基本原理</h4><p>将非线性自编码器和DNN结合，提高模型的非线性拟合能力，使得批次效应结果和其它因素影响结果分开，以在去除批次效应的同时保留更多生物学特征。<br>在AE模型的训练过程中，训练一个额外的分类器和排序器来对抗性正则化，潜在的特征被编码器提取出来，然后解码器在没有批次效应的情况下重建数据。  </p>
<h4 id="关键步骤-4"><a href="#关键步骤-4" class="headerlink" title="关键步骤"></a>关键步骤</h4><p>黑色实线和红色虚线分别表示反向传播算法的前向和后向计算步骤。蓝色虚线路径表示训练后的批量效应去除步骤。<br><img src="/2021/10/29/BatchEffect/NormAE.png" alt="NormAE原理图">  </p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Leek, Jeffrey T et al. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3880143/"><strong>Tackling the widespread and critical impact of batch effects in high-throughput data.</strong></a> Nature reviews. Genetics, vol. 11,10 (2010): 733-9.<br>[2] Čuklina, Jelena et al. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8447595/"><strong>Diagnostics and correction of batch effects in large-scale proteomic studies: a tutorial.</strong></a> Molecular systems biology, vol. 17,8 (2021): e10240.<br>[3] Zhou, Longjian et al. <a href="https://pubmed.ncbi.nlm.nih.gov/31611172/"><strong>Examining the practical limits of batch effect-correction algorithms: When should you care about batch effects?</strong></a>, Journal of Genetics and Genomics, Vol. 46, 9(2019): 433-443.<br>[4] Goh, Wilson Wen Bin et al. <a href="https://pubmed.ncbi.nlm.nih.gov/28351613/"><strong>Why Batch Effects Matter in Omics Data, and How to Avoid Them.</strong></a> Trends Biotechnol, Vol. 35, 6 (2017):498-507.<br>[5] Johnson, WE et al. <a href="https://academic.oup.com/biostatistics/article/8/1/118/252073/"><strong>Adjusting batch effects in microarray expression data using empirical Bayes methods.</strong></a> Biostatistics, Vol. 8, 1 (2007): 118–127.<br>[6] Dunn, W et al. <a href="https://www.nature.com/articles/nprot.2011.335/"><strong>Procedures for large-scale metabolic profiling of serum and plasma using gas chromatography and liquid chromatography coupled to mass spectrometry.</strong></a> Nature Protocol, 6 (2011): 1060–1083.<br>[7] Sompairac, Nicolas et al. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6771121/"><strong>Independent Component Analysis for Unraveling the Complexity of Cancer Omics Datasets.</strong></a> International journal of molecular sciences. vol. 20, 18 (2019): 4414.<br>[8] Deng, Kui et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0003267019301849/"><strong>WaveICA: A novel algorithm to remove batch effects for large-scale untargeted metabolomics data based on wavelet analysis.</strong></a> Analytica Chimica Acta, Vol. 1061, (2019): 60-69.<br>[9] Rong, Zhiwei et al. <a href="https://pubs.acs.org/doi/10.1021/acs.analchem.9b05460/"><strong>NormAE: Deep Adversarial Learning Model to Remove Batch Effects in Liquid Chromatography Mass Spectrometry-Based Metabolomics Data.</strong></a> Analytical Chemistry, Vol. 92, 7 (2020): 5082–5090.  </p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>BatchEffects</category>
      </categories>
      <tags>
        <tag>Bioinformatics</tag>
        <tag>BatchEffects</tag>
      </tags>
  </entry>
  <entry>
    <title>识别和消除批次效应的R包proBatch的使用</title>
    <url>/2021/11/08/proBatch/</url>
    <content><![CDATA[<center>proBatch: Tools for Diagnostics and Corrections of Batch Effects in Proteomics</center>
<span id="more"></span>

<h2 id="proBatch简介"><a href="#proBatch简介" class="headerlink" title="proBatch简介"></a>proBatch简介</h2><p>proBatch是便于在高通量实验中进行批量效应分析和校正的分析工具。主要为质谱蛋白质组学(DIA/SWATH)开发，但也可在调整后应用于大多数的Omic数据。<br>proBatch包含  </p>
<ul>
<li>诊断(蛋白质组/基因组范围和特征水平)  </li>
<li>校正(归一化和批次效应校正)  </li>
<li>基于非线性拟合的方法来处理复杂的、质谱特有的信号漂移</li>
<li>质量控制<br>功能。  </li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="安装所需的其它包"><a href="#安装所需的其它包" class="headerlink" title="安装所需的其它包"></a>安装所需的其它包</h3><p>proBatch主要通过调用其它包中的函数实现功能，因此依赖于许多其它已有的R包。如果其中一些包未安装，则需要在运行proBatch之前安装。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">bioc_deps &lt;- <span class="built_in">c</span>(<span class="string">&quot;GO.db&quot;</span>, <span class="string">&quot;impute&quot;</span>, <span class="string">&quot;preprocessCore&quot;</span>, <span class="string">&quot;pvca&quot;</span>,<span class="string">&quot;sva&quot;</span> )</span><br><span class="line">cran_deps &lt;- <span class="built_in">c</span>(<span class="string">&quot;corrplot&quot;</span>, <span class="string">&quot;data.table&quot;</span>, <span class="string">&quot;ggplot2&quot;</span>, <span class="string">&quot;ggfortify&quot;</span>,<span class="string">&quot;lazyeval&quot;</span>, <span class="string">&quot;lubridate&quot;</span>, <span class="string">&quot;pheatmap&quot;</span>, <span class="string">&quot;reshape2&quot;</span>,<span class="string">&quot;readr&quot;</span>, <span class="string">&quot;rlang&quot;</span>, <span class="string">&quot;tibble&quot;</span>, <span class="string">&quot;dplyr&quot;</span>, <span class="string">&quot;tidyr&quot;</span>, <span class="string">&quot;wesanderson&quot;</span>,<span class="string">&quot;WGCNA&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> (!requireNamespace(<span class="string">&quot;BiocManager&quot;</span>, quietly = <span class="literal">TRUE</span>))</span><br><span class="line">  install.packages(<span class="string">&quot;BiocManager&quot;</span>)</span><br><span class="line">BiocManager::install(bioc_deps)</span><br><span class="line">install.packages(cran_deps)</span><br></pre></td></tr></table></figure>
<h3 id="安装proBatch"><a href="#安装proBatch" class="headerlink" title="安装proBatch"></a>安装proBatch</h3><p>可通过以下三个途径获取proBatch包：  </p>
<ul>
<li><a href="https://www.bioconductor.org/packages/release/bioc/html/proBatch.html">Bioconductor</a>  <figure class="highlight r"><table><tr><td class="code"><pre><span class="line">    <span class="keyword">if</span> (!requireNamespace(<span class="string">&quot;BiocManager&quot;</span>, quietly = <span class="literal">TRUE</span>))</span><br><span class="line">        install.packages(<span class="string">&quot;BiocManager&quot;</span>)</span><br><span class="line"></span><br><span class="line">    BiocManager::install(<span class="string">&quot;proBatch&quot;</span>)</span><br><span class="line">    ```  </span><br><span class="line">- [Docker container](https://hub.docker.com/r/digitalproteomes/probatch)  </span><br><span class="line">- [GitHub repository](https://github.com/symbioticMe/batch_effects_workflow_code)  </span><br><span class="line">  ```R</span><br><span class="line">    library(devtools)</span><br><span class="line">    install_github(<span class="string">&quot;symbioticMe/proBatch&quot;</span>, build_vignettes = <span class="literal">TRUE</span>)</span><br></pre></td></tr></table></figure>
<h2 id="proBatch的使用"><a href="#proBatch的使用" class="headerlink" title="proBatch的使用"></a>proBatch的使用</h2>要查看与系统中安装的proBatch版本相对应的说明文档，启动R并输入:  <figure class="highlight r"><table><tr><td class="code"><pre><span class="line">browseVignettes(<span class="string">&quot;proBatch&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="使用前的tips"><a href="#使用前的tips" class="headerlink" title="使用前的tips"></a>使用前的tips</h3><ul>
<li>一些基本的数据处理步骤已经完成，如已经完成搜库比对、FDR control、log-transformation等  </li>
<li>数据过滤。应过滤掉诱饵测量值(decoy measurements)以确保正确的样本强度分布对齐。过滤掉低质量的样本(通常通过鉴定肽的总强度或样品的相关性来确定)  </li>
<li>建议在批次效应校正之前不要填补缺失值  </li>
<li>在消除批次效应之后再进行蛋白质定量  </li>
</ul>
<h3 id="Preparing-for-data-analysis"><a href="#Preparing-for-data-analysis" class="headerlink" title="Preparing for data analysis"></a>Preparing for data analysis</h3><h4 id="Loading-the-libraries"><a href="#Loading-the-libraries" class="headerlink" title="Loading the libraries"></a>Loading the libraries</h4><p>加载所需的包，以便后续步骤的使用。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">require(dplyr)</span><br><span class="line">require(tibble)</span><br><span class="line">require(ggplot2)</span><br><span class="line">library(proBatch)</span><br></pre></td></tr></table></figure>
<h4 id="Input-data"><a href="#Input-data" class="headerlink" title="Input data"></a>Input data</h4><p>数据分析需要三个数据表，即：  </p>
<ol>
<li>measurement (data matrix)  </li>
<li>sample annotation  </li>
<li>feature annotation (optional) tables  </li>
</ol>
<p>如果对BioBase数据比较熟悉，则可认为上述的三种数据是：  </p>
<ol>
<li>assayData  </li>
<li>joined phenoData and protocolData  </li>
<li>featureData  </li>
</ol>
<p>三种数据可参考包中给出的示例数据</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">data(<span class="string">&#x27;example_proteome&#x27;</span>, <span class="string">&#x27;example_sample_annotation&#x27;</span>, <span class="string">&#x27;example_peptide_annotation&#x27;</span>, package = <span class="string">&#x27;proBatch&#x27;</span>)  </span><br></pre></td></tr></table></figure>
<p>或<a href="http://www.bioconductor.org/packages/release/bioc/vignettes/proBatch/inst/doc/proBatch.pdf">proBatch overview</a>中的详细说明。  </p>
<h4 id="其它有用的函数"><a href="#其它有用的函数" class="headerlink" title="其它有用的函数"></a>其它有用的函数</h4><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Transforming the data to long or wide format</span></span><br><span class="line">example_matrix &lt;- long_to_matrix(example_proteome, feature_id_col = <span class="string">&#x27;peptide_group_label&#x27;</span>, measure_col = <span class="string">&#x27;Intensity&#x27;</span>, sample_id_col = <span class="string">&#x27;FullRunName&#x27;</span>)</span><br><span class="line"><span class="comment"># Transforming the data to log scale</span></span><br><span class="line"><span class="comment"># 零值会被保留为零</span></span><br><span class="line">log_transformed_matrix &lt;- log_transform_dm(example_matrix, log_base = <span class="number">2</span>, offset = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># Defining the color scheme</span></span><br><span class="line">color_list &lt;- sample_annotation_to_colors(example_sample_annotation, factor_columns = <span class="built_in">c</span>(<span class="string">&#x27;MS_batch&#x27;</span>, <span class="string">&#x27;digestion_batch&#x27;</span>, <span class="string">&#x27;EarTag&#x27;</span>, <span class="string">&#x27;Strain&#x27;</span>, <span class="string">&#x27;Diet&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>), numeric_columns = <span class="built_in">c</span>(<span class="string">&#x27;DateTime&#x27;</span>,<span class="string">&#x27;order&#x27;</span>))</span><br></pre></td></tr></table></figure>
<h3 id="Initial-assessment-of-the-raw-data-matrix"><a href="#Initial-assessment-of-the-raw-data-matrix" class="headerlink" title="Initial assessment of the raw data matrix"></a>Initial assessment of the raw data matrix</h3><h4 id="Plotting-the-sample-mean"><a href="#Plotting-the-sample-mean" class="headerlink" title="Plotting the sample mean"></a>Plotting the sample mean</h4><p>proBatch建议在处理批次效应之后再填补缺失值，但包中没有兼容存在缺失值的情况，如果有缺失值无法计算mean。<br><code>plot_sample_mean</code>函数主要实现的功能为计算样本均值并绘制样本均值散点图，横坐标为样本顺序(order)，纵坐标为样本均值(Mean_Intensity)，并以不同颜色表示样本的batch。可通过自行编写能够兼容缺失值的代码实现这一功能。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">plot_sample &lt;- data.frame(row.names = colnames(log_transformed_matrix))</span><br><span class="line">colnum &lt;- ncol(log_transformed_matrix)</span><br><span class="line"><span class="keyword">for</span>(i <span class="keyword">in</span> <span class="built_in">c</span>(<span class="number">1</span>:colnum))</span><br><span class="line">&#123;</span><br><span class="line">  item &lt;- colnames(log_transformed_matrix)[i]</span><br><span class="line">  plot_sample[item, <span class="string">&quot;mean&quot;</span>] &lt;- mean(log_transformed_matrix[,i], na.rm=<span class="built_in">T</span>)</span><br><span class="line">  plot_sample[item,<span class="string">&quot;MS_batch&quot;</span>] &lt;- sample_anno[i,<span class="string">&quot;MS_batch&quot;</span>]</span><br><span class="line">  plot_sample[item,<span class="string">&quot;order&quot;</span>] &lt;- sample_anno[i,<span class="string">&quot;order&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">ggplot(plot_sample, aes(order, mean, color = MS_batch)) + geom_point() + xlab(<span class="string">&quot;order&quot;</span>) + ylab(<span class="string">&quot;Mean_intensity&quot;</span>) + ylim(<span class="number">0</span>,<span class="number">15</span>)</span><br></pre></td></tr></table></figure>

<h4 id="Plotting-boxplots"><a href="#Plotting-boxplots" class="headerlink" title="Plotting boxplots"></a>Plotting boxplots</h4><p>绘制箱图观察数据：  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">log_transformed_long &lt;- matrix_to_long(log_transformed_matrix)</span><br><span class="line">batch_col = <span class="string">&#x27;MS_batch&#x27;</span></span><br><span class="line">plot_boxplot(log_transformed_long, example_sample_annotation, batch_col = batch_col, color_scheme = color_list[[batch_col]])</span><br></pre></td></tr></table></figure>
<p>利用PEAKS数据做到这一步时发现产生的箱图向0偏，即含有大量0值。这是PEAKS搜库结果的一个特点，除了缺失值还会有大量intensity被定量为0。在之前处理PEAKS数据时，log-transformation步骤会将0转换为NA，在后续步骤也当作缺失值处理。<br><img src="/2021/11/08/proBatch/value0.png" alt="含有大量0值"><br>而proBatch包针对的是openSWATH产生的tsv数据。该包中的函数<code>log_transform_dm</code>会将0保留为0，导致使用PEAKS数据画箱图时出现问题。返回log-transformation步骤使用自己写的处理代码处理数据后，箱图绘制与预期一致。<br><img src="/2021/11/08/proBatch/valueNA.png" alt="将0转换为NA">  </p>
<h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><p>包中提供Median Normalization和Quantiles Normalization，可直接使用。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Median Normalization</span></span><br><span class="line"><span class="comment"># If data has been log transformed</span></span><br><span class="line">median_normalized_matrix = normalize_data_dm(log_transformed_matrix, normalize_func = <span class="string">&#x27;medianCentering&#x27;</span>)</span><br><span class="line"><span class="comment"># if data hasn&#x27;t been log transformed</span></span><br><span class="line">median_normalized_matrix = normalize_data_dm(example_matrix, normalize_func = <span class="string">&#x27;medianCentering&#x27;</span>, log_base = <span class="number">2</span>, offset = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Quantile Normalization</span></span><br><span class="line">quantile_normalized_matrix = normalize_data_dm(log_transformed_matrix, normalize_func = <span class="string">&#x27;quantile&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>后续相应的画图观察处理后的数据时，应注意Inf值的影响。数据中如有<code>Inf</code>或<code>-Inf</code>，可通过<code>data[data == Inf] &lt;- NA</code>或<code>data[data == -Inf] &lt;- NA</code>将其替换。Inf出现是因为在log转换时没有处理好0值。  </p>
<h3 id="Diagnostics-of-batch-effects-in-normalized-data"><a href="#Diagnostics-of-batch-effects-in-normalized-data" class="headerlink" title="Diagnostics of batch effects in normalized data"></a>Diagnostics of batch effects in normalized data</h3><h4 id="Hierarchical-clustering-amp-heatmap"><a href="#Hierarchical-clustering-amp-heatmap" class="headerlink" title="Hierarchical clustering &amp; heatmap"></a>Hierarchical clustering &amp; heatmap</h4><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">selected_annotations &lt;- <span class="built_in">c</span>(<span class="string">&#x27;MS_batch&#x27;</span>, <span class="string">&#x27;digestion_batch&#x27;</span>, <span class="string">&#x27;Diet&#x27;</span>)</span><br><span class="line"><span class="comment"># Plot clustering between samples</span></span><br><span class="line">plot_hierarchical_clustering(quantile_normalized_matrix, sample_annotation = example_sample_annotation, color_list = color_list, factors_to_plot = selected_annotations, distance = <span class="string">&#x27;euclidean&#x27;</span>, agglomeration = <span class="string">&#x27;complete&#x27;</span>, label_samples = <span class="literal">FALSE</span>)</span><br><span class="line"><span class="comment"># Heatmap</span></span><br><span class="line">plot_heatmap_diagnostic(quantile_normalized_matrix, example_sample_annotation, factors_to_plot = selected_annotations, cluster_cols = <span class="literal">TRUE</span>, color_list = color_list, show_rownames = <span class="literal">FALSE</span>, show_colnames = <span class="literal">FALSE</span>)</span><br></pre></td></tr></table></figure>
<p>根据报错信息可知color_list一项一直与我的数据不兼容，因此注释行显示不完全。<br>修改color_list或根据数据需要重写聚类绘图函数即可。   </p>
<h4 id="PCA-amp-PVCA"><a href="#PCA-amp-PVCA" class="headerlink" title="PCA &amp; PVCA"></a>PCA &amp; PVCA</h4><p>PCA和PVCA使用时，缺失值会被直接填为-1。<br>PVCA对计算的要求很高，且耗时较长，尤其是数据量大的情况。建议在性能较好的机器上运行这一步骤。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pca</span></span><br><span class="line">pca1 = plot_PCA(median_normalized_matrix, sample_anno, color_by = <span class="string">&#x27;MS_batch&#x27;</span>, plot_title = <span class="string">&#x27;MS batch&#x27;</span>, color_scheme = color_list[[<span class="string">&#x27;MS_batch&#x27;</span>]])</span><br><span class="line">pca2 = plot_PCA(median_normalized_matrix, sample_anno, color_by = <span class="string">&#x27;digestion_batch&#x27;</span>, plot_title = <span class="string">&#x27;Digestion batch&#x27;</span>, color_scheme = color_list[[<span class="string">&#x27;digestion_batch&#x27;</span>]])</span><br><span class="line">pca3 = plot_PCA(median_normalized_matrix, sample_anno, color_by = <span class="string">&#x27;order&#x27;</span>, plot_title = <span class="string">&#x27;order&#x27;</span>, color_scheme = color_list[[<span class="string">&#x27;order&#x27;</span>]])</span><br><span class="line">pca4 = plot_PCA(median_normalized_matrix, sample_anno, color_by = <span class="string">&#x27;DateTime&#x27;</span>, plot_title = <span class="string">&#x27;DateTime&#x27;</span>, color_scheme = color_list[[<span class="string">&#x27;DateTime&#x27;</span>]])</span><br><span class="line">library(ggpubr)</span><br><span class="line">ggarrange(pca1, pca2, pca3, pca4, ncol = <span class="number">2</span>, nrow = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pvca</span></span><br><span class="line">technical_factors = <span class="built_in">c</span>(<span class="string">&#x27;MS_batch&#x27;</span>, <span class="string">&#x27;digestion_batch&#x27;</span>)</span><br><span class="line">biological_factors = <span class="literal">NULL</span></span><br><span class="line">biospecimen_id_col = <span class="string">&#x27;EarTag&#x27;</span></span><br><span class="line">plot_PVCA(median_normalized_matrix, sample_anno, technical_factors = technical_factors, biological_factors = biological_factors)</span><br></pre></td></tr></table></figure>

<h4 id="Peptide-level-diagnostics-and-spike-ins"><a href="#Peptide-level-diagnostics-and-spike-ins" class="headerlink" title="Peptide-level diagnostics and spike-ins"></a>Peptide-level diagnostics and spike-ins</h4><p>这一步骤需要将来自同一蛋白的肽段注释在一起。如果缺少肽段的注释信息，这一步骤无法正常进行。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">median_normalized_long &lt;- matrix_to_long(median_normalized_matrix)</span><br><span class="line">plot_spike_in(median_normalized_long, sample_anno, peptide_annotation = peptide_anno, protein_col = <span class="string">&#x27;Gene&#x27;</span>, spike_ins = <span class="string">&#x27;BOVINE_A1ag&#x27;</span>, plot_title = <span class="string">&#x27;Spike-in BOVINE protein peptides&#x27;</span>, color_by_batch = <span class="literal">TRUE</span>, color_scheme = color_list[[batch_col]])</span><br></pre></td></tr></table></figure>

<h3 id="correction-batch-effect"><a href="#correction-batch-effect" class="headerlink" title="correction batch effect"></a>correction batch effect</h3><h4 id="Continuous-drift-correction"><a href="#Continuous-drift-correction" class="headerlink" title="Continuous drift correction"></a>Continuous drift correction</h4><p>处理连续型批次效应使用LOESS拟合。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">loess_fit_df &lt;- adjust_batch_trend_df(quantile_normalized_long, example_sample_annotation)</span><br><span class="line">loess_fit_70 &lt;- adjust_batch_trend_df(median_normalized_long, sample_anno, span = <span class="number">0.7</span>)</span><br><span class="line">plot_with_fitting_curve(feature_name = <span class="string">&#x27;N(+.98)NATVHEQVGGPSLTSDLQAQSK&#x27;</span>, fit_df = loess_fit_70, fit_value_col = <span class="string">&#x27;fit&#x27;</span>, df_long = median_normalized_long, sample_annotation = sample_anno, color_by_batch = <span class="literal">TRUE</span>, color_scheme = color_list[[batch_col]], plot_title = <span class="string">&#x27;Span = 70%&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="Discrete-batch-correction"><a href="#Discrete-batch-correction" class="headerlink" title="Discrete batch correction"></a>Discrete batch correction</h4><p>处理离散型批次效应可通过median centering (per feature per batch)和ComBat进行。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># median centering</span></span><br><span class="line">peptide_median_df &lt;- center_feature_batch_medians_df(loess_fit_df, sample_anno)</span><br><span class="line">plot_single_feature(feature_name = <span class="string">&#x27;N(+.98)NATVHEQVGGPSLTSDLQAQSK&#x27;</span>, df_long = peptide_median_df, sample_annotation = sample_anno, measure_col = <span class="string">&#x27;Intensity&#x27;</span>, plot_title = <span class="string">&#x27;Feature-level Median Centered&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ComBat</span></span><br><span class="line">comBat_df &lt;- correct_with_ComBat_df(loess_fit_df, example_sample_annotation)</span><br><span class="line">plot_single_feature(feature_name = <span class="string">&#x27;10231_QDVDVWLWQQEGSSK_2&#x27;</span>, df_long = loess_fit_df, sample_annotation = example_sample_annotation, plot_title = <span class="string">&#x27;Loess Fitted&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="Correct-batch-effects-universal-function"><a href="#Correct-batch-effects-universal-function" class="headerlink" title="Correct batch effects: universal function"></a>Correct batch effects: universal function</h4><p>proBatch提供一个方便的多合一的函数来进行批量校正。<br>函数<code>correct_batch_effects_df()</code>能在一次函数调用中可修正MS信号漂移和离散位移。只需在<code>discrete_func</code>中指定首选的离散校正方法，即<code>&quot;ComBat &quot;</code>或 <code>&quot;MedianCentering&quot;</code>。并补充其他参数，如<code>adjust_batch_trend_df()</code>中的<code>span</code>、<code>abs_threshold</code>或<code>pct_threshold</code>。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">batch_corrected_df &lt;- correct_batch_effects_df(df_long = median_normalized_long, sample_annotation = sample_anno,discrete_func = <span class="string">&#x27;ComBat&#x27;</span>,continuous_func = <span class="string">&#x27;loess_regression&#x27;</span>,abs_threshold = <span class="number">5</span>, pct_threshold = <span class="number">0.20</span>)</span><br><span class="line">batch_corrected_matrix &lt;- long_to_matrix(batch_corrected_df)</span><br></pre></td></tr></table></figure>
<h3 id="Quality-control"><a href="#Quality-control" class="headerlink" title="Quality control"></a>Quality control</h3><h4 id="Heatmap-of-selected-replicate-samples"><a href="#Heatmap-of-selected-replicate-samples" class="headerlink" title="Heatmap of selected replicate samples"></a>Heatmap of selected replicate samples</h4><p>挑选重复组计算相关性并绘制热图观察批次效应处理结果。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># specify which samples to correlate</span></span><br><span class="line">earTags &lt;- <span class="built_in">c</span>(<span class="string">&#x27;ET1524&#x27;</span>, <span class="string">&#x27;ET2078&#x27;</span>, <span class="string">&#x27;ET1322&#x27;</span>, <span class="string">&#x27;ET1566&#x27;</span>, <span class="string">&#x27;ET1354&#x27;</span>, <span class="string">&#x27;ET1420&#x27;</span>, <span class="string">&#x27;ET2154&#x27;</span>, <span class="string">&#x27;ET1515&#x27;</span>, <span class="string">&#x27;ET1506&#x27;</span>, <span class="string">&#x27;ET2577&#x27;</span>, <span class="string">&#x27;ET1681&#x27;</span>, <span class="string">&#x27;ET1585&#x27;</span>, <span class="string">&#x27;ET1518&#x27;</span>, <span class="string">&#x27;ET1906&#x27;</span>)</span><br><span class="line">replicate_filenames = example_sample_annotation %&gt;% filter(MS_batch %in% <span class="built_in">c</span>(<span class="string">&#x27;Batch_2&#x27;</span>, <span class="string">&#x27;Batch_3&#x27;</span>)) %&gt;% filter(EarTag %in% earTags) %&gt;% pull(!!sym(<span class="string">&#x27;FullRunName&#x27;</span>))</span><br><span class="line"><span class="comment"># plot the ‘exploratory’ correlation matrix, which can be further beautified</span></span><br><span class="line">p1_exp = plot_sample_corr_heatmap(log_transformed_matrix, samples_to_plot = replicate_filenames, plot_title = <span class="string">&#x27;Correlation of selected samples&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># To ensure the color scale for correlation is consistent between two plots, we create a color vector and breaks</span></span><br><span class="line">breaksList &lt;- seq(<span class="number">0.7</span>, <span class="number">1</span>, by = <span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># color scale of pheatmap</span></span><br><span class="line">heatmap_colors = colorRampPalette(rev(RColorBrewer::brewer.pal(n = <span class="number">7</span>, name = <span class="string">&#x27;RdYlBu&#x27;</span>)))(<span class="built_in">length</span>(breaksList) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the heatmap with annotations for the chosen samples</span></span><br><span class="line">factors_to_show = <span class="built_in">c</span>(batch_col, biospecimen_id_col)</span><br><span class="line">p1 = plot_sample_corr_heatmap(log_transformed_matrix, samples_to_plot = replicate_filenames,sample_annotation = example_sample_annotation, factors_to_plot = factors_to_show, plot_title = <span class="string">&#x27;Log transformed correlation matrix of selected replicated samples&#x27;</span>, color_list = color_list, heatmap_color = heatmap_colors, breaks = breaksList, cluster_rows= <span class="literal">FALSE</span>, cluster_cols=<span class="literal">FALSE</span>,fontsize = <span class="number">4</span>, annotation_names_col = <span class="literal">TRUE</span>, annotation_legend = <span class="literal">FALSE</span>, show_colnames = <span class="literal">FALSE</span>)</span><br><span class="line">p2 = plot_sample_corr_heatmap(batch_corrected_matrix, samples_to_plot = replicate_filenames, sample_annotation = example_sample_annotation, factors_to_plot = factors_to_show, plot_title = <span class="string">&#x27;Batch Corrected selected replicated samples&#x27;</span>, color_list = color_list, heatmap_color = heatmap_colors, breaks = breaksList, cluster_rows= <span class="literal">FALSE</span>, cluster_cols=<span class="literal">FALSE</span>,fontsize = <span class="number">4</span>, annotation_names_col = <span class="literal">TRUE</span>, annotation_legend = <span class="literal">FALSE</span>, show_colnames = <span class="literal">FALSE</span>)</span><br><span class="line">library(gridExtra)</span><br><span class="line">grid.arrange(grobs = <span class="built_in">list</span>(p1$gtable, p2$gtable), ncol=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>由于缺失值的存在，直接使用包中函数进行这一步骤失败，自己写代码代替。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">library(pheatmap)</span><br><span class="line"><span class="comment"># 计算样本间的相关性</span></span><br><span class="line"><span class="comment"># completel.obs: 计算所有样本间overlap的部分，如果某一行有缺失值则这一行不加入计算</span></span><br><span class="line">mcor &lt;- cor(select_replicate_samples, method = <span class="string">&#x27;pearson&#x27;</span>, use = <span class="string">&quot;complete.obs&quot;</span>)</span><br><span class="line">pheatmap(mcor, cellwidth = <span class="number">25</span>, cellheight = <span class="number">25</span>, color = colorRampPalette(<span class="built_in">c</span>(<span class="string">&quot;#ffffff&quot;</span>, <span class="string">&quot;#4682b4&quot;</span>))(<span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<h4 id="Correlation-distribution-of-samples"><a href="#Correlation-distribution-of-samples" class="headerlink" title="Correlation distribution of samples"></a>Correlation distribution of samples</h4><p>绘制相同或不同批次的生物重复和非生物重复之间的相关分布。<br>样本相关性的比较不应该通过评估重复组内与批次内校正的单个例子来进行，而应该通过比较分布来进行。除非这些例子是在整个分布结构的背景下显示的，否则它们会导致错误的结论。样品相关性经常被用来证明测量的质量，因为它通常是非常高的(重复组相关性超过0.95的例子在质谱分析中很常见)。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">sample_cor_raw &lt;- plot_sample_corr_distribution(log_transformed_matrix, example_sample_annotation,repeated_samples = replicate_filenames, batch_col = <span class="string">&#x27;MS_batch&#x27;</span>, biospecimen_id_col = <span class="string">&#x27;EarTag&#x27;</span>, plot_title = <span class="string">&#x27;Correlation of samples (raw)&#x27;</span>, plot_param = <span class="string">&#x27;batch_replicate&#x27;</span>)</span><br><span class="line">raw_corr = sample_cor_raw + theme(axis.text.x = element_text(angle = <span class="number">45</span>, hjust = <span class="number">1</span>)) + ylim(<span class="number">0.7</span>,<span class="number">1</span>) + xlab(<span class="literal">NULL</span>)</span><br><span class="line">sample_cor_batchCor &lt;- plot_sample_corr_distribution(batch_corrected_matrix, example_sample_annotation, batch_col = <span class="string">&#x27;MS_batch&#x27;</span>, plot_title = <span class="string">&#x27;Batch corrected&#x27;</span>, plot_param = <span class="string">&#x27;batch_replicate&#x27;</span>)</span><br><span class="line">corr_corr = sample_cor_batchCor + theme(axis.text.x = element_text(angle = <span class="number">45</span>, hjust = <span class="number">1</span>)) + ylim(<span class="number">0.7</span>, <span class="number">1</span>) + xlab(<span class="literal">NULL</span>)</span><br><span class="line">library(gtable)</span><br><span class="line">library(grid)</span><br><span class="line">g2 &lt;- ggplotGrob(raw_corr)</span><br><span class="line">g3 &lt;- ggplotGrob(corr_corr)</span><br><span class="line">g &lt;- cbind(g2, g3, size = <span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">grid.draw(g)</span><br></pre></td></tr></table></figure>

<h4 id="Correlation-of-peptide-distributions-within-and-between-proteins"><a href="#Correlation-of-peptide-distributions-within-and-between-proteins" class="headerlink" title="Correlation of peptide distributions within and between proteins"></a>Correlation of peptide distributions within and between proteins</h4><p>来自同一蛋白的肽段之间会有更强的相关性，通过计算蛋白内和蛋白间肽段的相关性观察批次效应处理结果。<br>这一步骤对计算的要求较高，且数据量大时耗时较长。建议使用性能较好的电脑进行这一步骤的计算。  </p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">peptide_cor_raw &lt;- plot_peptide_corr_distribution(log_transformed_matrix, example_peptide_annotation, protein_col = <span class="string">&#x27;Gene&#x27;</span>, plot_title = <span class="string">&#x27;Peptide correlation (raw)&#x27;</span>)</span><br><span class="line">peptide_cor_batchCor &lt;- plot_peptide_corr_distribution(batch_corrected_matrix, example_peptide_annotation, protein_col = <span class="string">&#x27;Gene&#x27;</span>, plot_title = <span class="string">&#x27;Peptide correlation (batch correcte)&#x27;</span>)</span><br><span class="line">g2 &lt;- ggplotGrob(peptide_cor_raw+ ylim(<span class="built_in">c</span>(-<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">g3 &lt;- ggplotGrob(peptide_cor_batchCor+ ylim(<span class="built_in">c</span>(-<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">g &lt;- cbind(g2, g3, size = <span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">grid.draw(g)</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="http://www.bioconductor.org/packages/release/bioc/manuals/proBatch/man/proBatch.pdf">proBatch Manual</a><br>[2] <a href="http://www.bioconductor.org/packages/release/bioc/vignettes/proBatch/inst/doc/proBatch.pdf">proBatch Overview</a>  </p>
]]></content>
      <categories>
        <category>Tools</category>
        <category>proBatch</category>
      </categories>
      <tags>
        <tag>Rpackage</tag>
        <tag>BatchEffect</tag>
      </tags>
  </entry>
</search>
